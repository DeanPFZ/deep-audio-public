{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/magenta/models/nsynth/wavenet/masked.py:115: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from preprocess import Audio_Processor\n",
    "import data_utils as du\n",
    "from sklearn import metrics\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from classification_plots import plot_confusion_matrix, plot_learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Able to specify which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "SR = 16000\n",
    "blocksize = int(SR)\n",
    "overlap = int(SR/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = '../ESC-50/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_db='../ESC-50/'\n",
    "ps = Audio_Processor(path_to_db + 'audio/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Here we load the csv that describes each file in the dataset. We add a high level category that is defined in the ESC-50 documentation. This we realize is anthetical to true training, it is a stopgap for when we use NLP to classify tags into these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(path_to_db + 'meta/esc50.csv')\n",
    "classes = [None] * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_classes = ['Human & Animal', 'Interacting Materials']\n",
    "mapping = {'dog': 0,'rooster': 0,'pig': 0,'cow': 0,'frog': 0,'cat': 0,'hen': 0,\n",
    "            'insects': 0,'sheep': 0,'crow': 0,'rain': 1,'sea_waves': 1,'crackling_fire': 1,\n",
    "            'crickets': 0,'chirping_birds': 0,'water_drops': 1,'wind': 1,'pouring_water': 1,\n",
    "            'toilet_flush': 1,'thunderstorm': 1,'crying_baby': 0,'sneezing': 0,'clapping': 0,\n",
    "            'breathing': 0,'coughing': 0,'footsteps': 1,'laughing': 0,'brushing_teeth': 1,\n",
    "            'snoring': 0,'drinking_sipping': 1,'door_wood_knock': 1,'mouse_click': 1,\n",
    "            'keyboard_typing': 1,'door_wood_creaks': 1,'can_opening': 1,'washing_machine': 1,\n",
    "            'vacuum_cleaner': 1,'clock_alarm': 1,'clock_tick': 1,'glass_breaking':1,'helicopter': 1,\n",
    "            'chainsaw': 1,'siren': 1,'car_horn': 1,'engine': 1,'train': 1,'church_bells': 1,\n",
    "            'airplane': 1,'fireworks': 1,'hand_saw': 1,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['h_target'] = None\n",
    "for index, row in dataset.iterrows():\n",
    "    target = row['target']\n",
    "    classes[target] = row['category']\n",
    "    dataset.loc[index, 'h_target'] = mapping[row['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "      <th>h_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take  \\\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A   \n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A   \n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A   \n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B   \n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A   \n",
       "\n",
       "   h_target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Preprocessed Data\n",
    "We allow for previously preprocessed data to be retrieved for faster training turnaround. If the fold has been preprocessed, it is loaded but if not it is processed and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess file not found, building new one\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.3378\n",
      "\tBytes: 64080\n",
      "\tProcessing Time: 350.02630043029785\n"
     ]
    }
   ],
   "source": [
    "df = ps.preprocess_fold(dataset, \n",
    "                        kind='mfcc', \n",
    "                        fld=range(1,5),\n",
    "                        blocksize=blocksize, \n",
    "                        overlap=overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ps.bag_of_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_2_std</th>\n",
       "      <th>mfcc_2_mean</th>\n",
       "      <th>mfcc_2_noise</th>\n",
       "      <th>mfcc_3_std</th>\n",
       "      <th>mfcc_3_mean</th>\n",
       "      <th>mfcc_3_noise</th>\n",
       "      <th>mfcc_4_std</th>\n",
       "      <th>mfcc_4_mean</th>\n",
       "      <th>mfcc_4_noise</th>\n",
       "      <th>mfcc_5_std</th>\n",
       "      <th>...</th>\n",
       "      <th>sflat_mean</th>\n",
       "      <th>sflat_noise</th>\n",
       "      <th>sroll_std</th>\n",
       "      <th>sroll_mean</th>\n",
       "      <th>sroll_noise</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_noise</th>\n",
       "      <th>h_target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68.392176</td>\n",
       "      <td>41.626128</td>\n",
       "      <td>34.414113</td>\n",
       "      <td>29.584520</td>\n",
       "      <td>26.704804</td>\n",
       "      <td>26.403885</td>\n",
       "      <td>26.030799</td>\n",
       "      <td>25.986042</td>\n",
       "      <td>25.584837</td>\n",
       "      <td>25.071507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023051</td>\n",
       "      <td>-0.027111</td>\n",
       "      <td>-0.025023</td>\n",
       "      <td>15.921645</td>\n",
       "      <td>28.230562</td>\n",
       "      <td>5.957012</td>\n",
       "      <td>25.264967</td>\n",
       "      <td>4.442260</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.503678</td>\n",
       "      <td>15.683141</td>\n",
       "      <td>16.213026</td>\n",
       "      <td>14.748283</td>\n",
       "      <td>14.982433</td>\n",
       "      <td>15.462390</td>\n",
       "      <td>15.502125</td>\n",
       "      <td>16.015013</td>\n",
       "      <td>16.049969</td>\n",
       "      <td>15.645559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058492</td>\n",
       "      <td>0.063429</td>\n",
       "      <td>0.060124</td>\n",
       "      <td>8.000755</td>\n",
       "      <td>12.302128</td>\n",
       "      <td>3.587324</td>\n",
       "      <td>13.066003</td>\n",
       "      <td>2.625496</td>\n",
       "      <td>0.485538</td>\n",
       "      <td>14.435381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.765703</td>\n",
       "      <td>2.219900</td>\n",
       "      <td>1.925966</td>\n",
       "      <td>1.607934</td>\n",
       "      <td>1.037395</td>\n",
       "      <td>1.379451</td>\n",
       "      <td>1.220553</td>\n",
       "      <td>1.246647</td>\n",
       "      <td>1.325921</td>\n",
       "      <td>1.247453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295605</td>\n",
       "      <td>-0.401249</td>\n",
       "      <td>-0.356166</td>\n",
       "      <td>5.815685</td>\n",
       "      <td>11.600177</td>\n",
       "      <td>1.946171</td>\n",
       "      <td>9.726162</td>\n",
       "      <td>0.533410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.908604</td>\n",
       "      <td>29.867657</td>\n",
       "      <td>20.699574</td>\n",
       "      <td>16.005048</td>\n",
       "      <td>12.305186</td>\n",
       "      <td>11.513304</td>\n",
       "      <td>11.091351</td>\n",
       "      <td>10.398829</td>\n",
       "      <td>10.122304</td>\n",
       "      <td>9.556914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058599</td>\n",
       "      <td>-0.065608</td>\n",
       "      <td>-0.061466</td>\n",
       "      <td>10.670691</td>\n",
       "      <td>20.339672</td>\n",
       "      <td>3.870926</td>\n",
       "      <td>16.950437</td>\n",
       "      <td>2.495087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67.472404</td>\n",
       "      <td>41.097861</td>\n",
       "      <td>32.082370</td>\n",
       "      <td>27.808841</td>\n",
       "      <td>25.057627</td>\n",
       "      <td>24.004113</td>\n",
       "      <td>24.603462</td>\n",
       "      <td>24.603316</td>\n",
       "      <td>24.236682</td>\n",
       "      <td>24.490926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021384</td>\n",
       "      <td>-0.020390</td>\n",
       "      <td>-0.019264</td>\n",
       "      <td>13.862573</td>\n",
       "      <td>24.801168</td>\n",
       "      <td>4.987959</td>\n",
       "      <td>21.800416</td>\n",
       "      <td>4.163241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>87.370475</td>\n",
       "      <td>52.330421</td>\n",
       "      <td>46.148207</td>\n",
       "      <td>41.723490</td>\n",
       "      <td>40.095945</td>\n",
       "      <td>40.549712</td>\n",
       "      <td>40.420141</td>\n",
       "      <td>40.441647</td>\n",
       "      <td>39.880189</td>\n",
       "      <td>39.417506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014911</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.014708</td>\n",
       "      <td>18.957784</td>\n",
       "      <td>33.510561</td>\n",
       "      <td>7.032860</td>\n",
       "      <td>29.323586</td>\n",
       "      <td>5.806976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>152.990931</td>\n",
       "      <td>94.887900</td>\n",
       "      <td>92.678212</td>\n",
       "      <td>76.212504</td>\n",
       "      <td>75.001668</td>\n",
       "      <td>76.185901</td>\n",
       "      <td>84.761325</td>\n",
       "      <td>94.589380</td>\n",
       "      <td>106.607614</td>\n",
       "      <td>105.094272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166657</td>\n",
       "      <td>0.162462</td>\n",
       "      <td>0.210591</td>\n",
       "      <td>104.656613</td>\n",
       "      <td>187.004716</td>\n",
       "      <td>57.626973</td>\n",
       "      <td>180.179270</td>\n",
       "      <td>24.324563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mfcc_2_std  mfcc_2_mean  mfcc_2_noise   mfcc_3_std  mfcc_3_mean  \\\n",
       "count  1600.000000  1600.000000   1600.000000  1600.000000  1600.000000   \n",
       "mean     68.392176    41.626128     34.414113    29.584520    26.704804   \n",
       "std      26.503678    15.683141     16.213026    14.748283    14.982433   \n",
       "min       2.765703     2.219900      1.925966     1.607934     1.037395   \n",
       "25%      46.908604    29.867657     20.699574    16.005048    12.305186   \n",
       "50%      67.472404    41.097861     32.082370    27.808841    25.057627   \n",
       "75%      87.370475    52.330421     46.148207    41.723490    40.095945   \n",
       "max     152.990931    94.887900     92.678212    76.212504    75.001668   \n",
       "\n",
       "       mfcc_3_noise   mfcc_4_std  mfcc_4_mean  mfcc_4_noise   mfcc_5_std  \\\n",
       "count   1600.000000  1600.000000  1600.000000   1600.000000  1600.000000   \n",
       "mean      26.403885    26.030799    25.986042     25.584837    25.071507   \n",
       "std       15.462390    15.502125    16.015013     16.049969    15.645559   \n",
       "min        1.379451     1.220553     1.246647      1.325921     1.247453   \n",
       "25%       11.513304    11.091351    10.398829     10.122304     9.556914   \n",
       "50%       24.004113    24.603462    24.603316     24.236682    24.490926   \n",
       "75%       40.549712    40.420141    40.441647     39.880189    39.417506   \n",
       "max       76.185901    84.761325    94.589380    106.607614   105.094272   \n",
       "\n",
       "          ...        sflat_mean  sflat_noise    sroll_std   sroll_mean  \\\n",
       "count     ...       1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "mean      ...         -0.023051    -0.027111    -0.025023    15.921645   \n",
       "std       ...          0.058492     0.063429     0.060124     8.000755   \n",
       "min       ...         -0.295605    -0.401249    -0.356166     5.815685   \n",
       "25%       ...         -0.058599    -0.065608    -0.061466    10.670691   \n",
       "50%       ...         -0.021384    -0.020390    -0.019264    13.862573   \n",
       "75%       ...          0.014911     0.015624     0.014708    18.957784   \n",
       "max       ...          0.166657     0.162462     0.210591   104.656613   \n",
       "\n",
       "       sroll_noise     rmse_std    rmse_mean   rmse_noise     h_target  \\\n",
       "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "mean     28.230562     5.957012    25.264967     4.442260     0.620000   \n",
       "std      12.302128     3.587324    13.066003     2.625496     0.485538   \n",
       "min      11.600177     1.946171     9.726162     0.533410     0.000000   \n",
       "25%      20.339672     3.870926    16.950437     2.495087     0.000000   \n",
       "50%      24.801168     4.987959    21.800416     4.163241     1.000000   \n",
       "75%      33.510561     7.032860    29.323586     5.806976     1.000000   \n",
       "max     187.004716    57.626973   180.179270    24.324563     1.000000   \n",
       "\n",
       "            target  \n",
       "count  1600.000000  \n",
       "mean     24.500000  \n",
       "std      14.435381  \n",
       "min       0.000000  \n",
       "25%      12.000000  \n",
       "50%      24.500000  \n",
       "75%      37.000000  \n",
       "max      49.000000  \n",
       "\n",
       "[8 rows x 131 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test, = train_test_split(\n",
    "                        df, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop(['target', 'h_target'], axis=1)\n",
    "train_y = train['h_target']\n",
    "test_X = test.drop(['target', 'h_target'], axis=1)\n",
    "test_y = test['h_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow Net\n",
    "Separate into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "def gpu_mfcc_deep_net_a():\n",
    "    # Create Model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(129,)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 10,945\n",
      "Trainable params: 10,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1088 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "1088/1088 [==============================] - 1s 466us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 2/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 3/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 4/200\n",
      "1088/1088 [==============================] - 0s 33us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 5/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 6/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 7/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 8/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 9/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 10/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 11/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 12/200\n",
      "1088/1088 [==============================] - 0s 32us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 13/200\n",
      "1088/1088 [==============================] - 0s 32us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 14/200\n",
      "1088/1088 [==============================] - 0s 32us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 15/200\n",
      "1088/1088 [==============================] - 0s 32us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 16/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 17/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 18/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 19/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 20/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 21/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 22/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 23/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 24/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 25/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 26/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 27/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 28/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 29/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 30/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 31/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 32/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 33/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 34/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 35/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 36/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 37/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 38/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 39/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 40/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 41/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 42/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 43/200\n",
      "1088/1088 [==============================] - 0s 32us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 44/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 45/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 46/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 47/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 48/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 49/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 50/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 51/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 52/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 54/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 55/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 56/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 57/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 58/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 59/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 60/200\n",
      "1088/1088 [==============================] - 0s 25us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 61/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 62/200\n",
      "1088/1088 [==============================] - 0s 32us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 63/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 64/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 65/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 66/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 67/200\n",
      "1088/1088 [==============================] - 0s 32us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 68/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 69/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 70/200\n",
      "1088/1088 [==============================] - 0s 33us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 71/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 72/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 73/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 74/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 75/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 76/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 77/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 78/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 79/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 80/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 81/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 82/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 83/200\n",
      "1088/1088 [==============================] - 0s 25us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 84/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 85/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 86/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 87/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 88/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 89/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 90/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 91/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 92/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 93/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 94/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 95/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 96/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 97/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 98/200\n",
      "1088/1088 [==============================] - 0s 32us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 99/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 100/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 101/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 102/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 103/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 104/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 105/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 106/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 107/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 108/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 109/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 110/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 111/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 112/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 114/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 115/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 116/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 117/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 118/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 119/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 120/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 121/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 122/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 123/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 124/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 125/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 126/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 127/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 128/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 129/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 130/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 131/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 132/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 133/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 134/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 135/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 136/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 137/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 138/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 139/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 140/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 141/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 142/200\n",
      "1088/1088 [==============================] - 0s 31us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 143/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 144/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 145/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 146/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 147/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 148/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 149/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 150/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 151/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 152/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 153/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 154/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 155/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 156/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 157/200\n",
      "1088/1088 [==============================] - 0s 32us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 158/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 159/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 160/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 161/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 162/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 163/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 164/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 165/200\n",
      "1088/1088 [==============================] - 0s 25us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 166/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 167/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 168/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 169/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 170/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 171/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 173/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 174/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 175/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 176/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 177/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 178/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 179/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 180/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 181/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 182/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 183/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 184/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 185/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 186/200\n",
      "1088/1088 [==============================] - 0s 30us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 187/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 188/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 189/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 190/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 191/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 192/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 193/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 194/200\n",
      "1088/1088 [==============================] - 0s 26us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 195/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 196/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 197/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 198/200\n",
      "1088/1088 [==============================] - 0s 29us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 199/200\n",
      "1088/1088 [==============================] - 0s 27us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n",
      "Epoch 200/200\n",
      "1088/1088 [==============================] - 0s 28us/step - loss: 5.9344 - acc: 0.6278 - val_loss: 5.8123 - val_acc: 0.6354\n"
     ]
    }
   ],
   "source": [
    "anim = KerasClassifier(build_fn=gpu_mfcc_deep_net_a, \n",
    "                       epochs=200, \n",
    "                       batch_size=128, \n",
    "                       validation_split=0.15)\n",
    "history = anim.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "# plt.ylim([0,9])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "# plt.ylim([0,9])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.584375\n",
      "Confusion matrix, without normalization\n",
      "[[  0 133]\n",
      " [  0 187]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = anim.predict(test_X)\n",
    "print(metrics.accuracy_score(test_y, pred))\n",
    "cm = metrics.confusion_matrix(test_y, pred)\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, h_classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = ps.preprocess_fold(dataset, \n",
    "                        kind='mfcc', \n",
    "                        fld=1, \n",
    "                        blocksize=blocksize, \n",
    "                        overlap=overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_df.drop(['target', 'h_target'], axis=1)\n",
    "y = all_df['h_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = anim.predict(X)\n",
    "print(metrics.accuracy_score(y, pred))\n",
    "cm = metrics.confusion_matrix(y, pred)\n",
    "plt.figure(figsize=(20,20))\n",
    "plot_confusion_matrix(cm, h_classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
