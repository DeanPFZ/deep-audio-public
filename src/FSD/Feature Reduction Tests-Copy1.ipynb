{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/magenta/models/nsynth/wavenet/masked.py:115: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import pandas as pd\n",
    "from preprocess import Audio_Processor\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import balanced_supersample, balanced_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000\n",
    "blocksize = int(SR/2)\n",
    "overlap = int(SR/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_db='../../ESC-50/'\n",
    "ps = Audio_Processor(path_to_db + 'audio/', sr=SR)\n",
    "dataset = pd.read_csv(path_to_db + 'meta/esc50.csv')\n",
    "classes = [None] * 50\n",
    "h_classes = ['Human & Animal', 'Interacting Materials']\n",
    "mapping = {\n",
    "    'dog': 0,\n",
    "    'rooster': 0,\n",
    "    'pig': 0,\n",
    "    'cow': 0,\n",
    "    'frog': 0,\n",
    "    'cat': 0,\n",
    "    'hen': 0,\n",
    "    'insects': 0,\n",
    "    'sheep': 0,\n",
    "    'crow': 0,\n",
    "    'rain': 1,\n",
    "    'sea_waves': 1,\n",
    "    'crackling_fire': 1,\n",
    "    'crickets': 0,\n",
    "    'chirping_birds': 0,\n",
    "    'water_drops': 1,\n",
    "    'wind': 1,\n",
    "    'pouring_water': 1,\n",
    "    'toilet_flush': 1,\n",
    "    'thunderstorm': 1,\n",
    "    'crying_baby': 0,\n",
    "    'sneezing': 0,\n",
    "    'clapping': 1,\n",
    "    'breathing': 0,\n",
    "    'coughing': 0,\n",
    "    'footsteps': 1,\n",
    "    'laughing': 0,\n",
    "    'brushing_teeth': 1,\n",
    "    'snoring': 0,\n",
    "    'drinking_sipping': 1,\n",
    "    'door_wood_knock': 1,\n",
    "    'mouse_click': 1,\n",
    "    'keyboard_typing': 1,\n",
    "    'door_wood_creaks': 1,\n",
    "    'can_opening': 1,\n",
    "    'washing_machine': 1,\n",
    "    'vacuum_cleaner': 1,\n",
    "    'clock_alarm': 1,\n",
    "    'clock_tick': 1,\n",
    "    'glass_breaking':1,\n",
    "    'helicopter': 1,\n",
    "    'chainsaw': 1,\n",
    "    'siren': 1,\n",
    "    'car_horn': 1,\n",
    "    'engine': 1,\n",
    "    'train': 1,\n",
    "    'church_bells': 1,\n",
    "    'airplane': 1,\n",
    "    'fireworks': 1,\n",
    "    'hand_saw': 1,\n",
    "}\n",
    "dataset['h_target'] = None\n",
    "for index, row in dataset.iterrows():\n",
    "    target = row['target']\n",
    "    classes[target] = row['category']\n",
    "    dataset.loc[index, 'h_target'] = mapping[row['category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Preprocessed Data\n",
    "We allow for previously preprocessed data to be retrieved for faster training turnaround. If the fold has been preprocessed, it is loaded but if not it is processed and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ps.preprocess_fold(dataset, \n",
    "                        kind='mfcc', \n",
    "                        blocksize=blocksize, \n",
    "                        overlap=overlap\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_2_std</th>\n",
       "      <th>mfcc_2_mean</th>\n",
       "      <th>mfcc_2_noise</th>\n",
       "      <th>mfcc_3_std</th>\n",
       "      <th>mfcc_3_mean</th>\n",
       "      <th>mfcc_3_noise</th>\n",
       "      <th>mfcc_4_std</th>\n",
       "      <th>mfcc_4_mean</th>\n",
       "      <th>mfcc_4_noise</th>\n",
       "      <th>mfcc_5_std</th>\n",
       "      <th>...</th>\n",
       "      <th>sflat_mean</th>\n",
       "      <th>sflat_noise</th>\n",
       "      <th>sroll_std</th>\n",
       "      <th>sroll_mean</th>\n",
       "      <th>sroll_noise</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_noise</th>\n",
       "      <th>h_target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.094700e+04</td>\n",
       "      <td>3.094700e+04</td>\n",
       "      <td>3.094700e+04</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.719667</td>\n",
       "      <td>46.264479</td>\n",
       "      <td>38.909376</td>\n",
       "      <td>33.446607</td>\n",
       "      <td>30.420424</td>\n",
       "      <td>30.067026</td>\n",
       "      <td>29.524960</td>\n",
       "      <td>29.485805</td>\n",
       "      <td>29.035557</td>\n",
       "      <td>28.434550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.535995e-02</td>\n",
       "      <td>-1.984839e-02</td>\n",
       "      <td>-1.938723e-02</td>\n",
       "      <td>14.260070</td>\n",
       "      <td>25.679845</td>\n",
       "      <td>5.237762</td>\n",
       "      <td>22.727680</td>\n",
       "      <td>4.911355</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>24.927586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.473942</td>\n",
       "      <td>18.374510</td>\n",
       "      <td>17.074185</td>\n",
       "      <td>14.922491</td>\n",
       "      <td>14.885459</td>\n",
       "      <td>15.237449</td>\n",
       "      <td>15.111426</td>\n",
       "      <td>15.600575</td>\n",
       "      <td>15.600374</td>\n",
       "      <td>15.252728</td>\n",
       "      <td>...</td>\n",
       "      <td>2.086369e-01</td>\n",
       "      <td>2.085811e-01</td>\n",
       "      <td>2.070859e-01</td>\n",
       "      <td>22.763022</td>\n",
       "      <td>35.058448</td>\n",
       "      <td>15.400834</td>\n",
       "      <td>17.316189</td>\n",
       "      <td>3.410737</td>\n",
       "      <td>0.467754</td>\n",
       "      <td>14.392002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.723873e-01</td>\n",
       "      <td>-7.458212e-01</td>\n",
       "      <td>-7.421038e-01</td>\n",
       "      <td>3.736712</td>\n",
       "      <td>6.454405</td>\n",
       "      <td>1.436722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54.270596</td>\n",
       "      <td>34.628251</td>\n",
       "      <td>27.134954</td>\n",
       "      <td>22.152604</td>\n",
       "      <td>17.779317</td>\n",
       "      <td>16.509955</td>\n",
       "      <td>16.142753</td>\n",
       "      <td>15.170072</td>\n",
       "      <td>14.981445</td>\n",
       "      <td>14.189170</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610912e-01</td>\n",
       "      <td>-1.659554e-01</td>\n",
       "      <td>-1.654091e-01</td>\n",
       "      <td>9.477854</td>\n",
       "      <td>17.833900</td>\n",
       "      <td>3.478282</td>\n",
       "      <td>14.893102</td>\n",
       "      <td>2.640077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74.850493</td>\n",
       "      <td>46.716638</td>\n",
       "      <td>38.133677</td>\n",
       "      <td>33.581847</td>\n",
       "      <td>30.752174</td>\n",
       "      <td>30.586093</td>\n",
       "      <td>30.338455</td>\n",
       "      <td>30.395567</td>\n",
       "      <td>30.146264</td>\n",
       "      <td>29.760050</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.367921e-09</td>\n",
       "      <td>-5.277997e-09</td>\n",
       "      <td>-8.137921e-09</td>\n",
       "      <td>11.984384</td>\n",
       "      <td>21.852503</td>\n",
       "      <td>4.507795</td>\n",
       "      <td>18.785621</td>\n",
       "      <td>4.292363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>93.894152</td>\n",
       "      <td>58.166543</td>\n",
       "      <td>50.129512</td>\n",
       "      <td>44.366403</td>\n",
       "      <td>41.731754</td>\n",
       "      <td>42.094875</td>\n",
       "      <td>41.359002</td>\n",
       "      <td>41.674235</td>\n",
       "      <td>40.984961</td>\n",
       "      <td>40.346104</td>\n",
       "      <td>...</td>\n",
       "      <td>1.205989e-01</td>\n",
       "      <td>1.163689e-01</td>\n",
       "      <td>1.146088e-01</td>\n",
       "      <td>15.742905</td>\n",
       "      <td>27.626522</td>\n",
       "      <td>5.601991</td>\n",
       "      <td>25.275695</td>\n",
       "      <td>6.459832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>208.957500</td>\n",
       "      <td>123.849951</td>\n",
       "      <td>118.728586</td>\n",
       "      <td>92.085252</td>\n",
       "      <td>89.965195</td>\n",
       "      <td>89.935857</td>\n",
       "      <td>113.100970</td>\n",
       "      <td>118.224343</td>\n",
       "      <td>120.085079</td>\n",
       "      <td>113.077150</td>\n",
       "      <td>...</td>\n",
       "      <td>8.057657e-01</td>\n",
       "      <td>8.572066e-01</td>\n",
       "      <td>7.961318e-01</td>\n",
       "      <td>2206.362673</td>\n",
       "      <td>5031.091987</td>\n",
       "      <td>2444.047253</td>\n",
       "      <td>620.895529</td>\n",
       "      <td>156.366775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mfcc_2_std   mfcc_2_mean  mfcc_2_noise    mfcc_3_std   mfcc_3_mean  \\\n",
       "count  30947.000000  30947.000000  30947.000000  30947.000000  30947.000000   \n",
       "mean      73.719667     46.264479     38.909376     33.446607     30.420424   \n",
       "std       30.473942     18.374510     17.074185     14.922491     14.885459   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       54.270596     34.628251     27.134954     22.152604     17.779317   \n",
       "50%       74.850493     46.716638     38.133677     33.581847     30.752174   \n",
       "75%       93.894152     58.166543     50.129512     44.366403     41.731754   \n",
       "max      208.957500    123.849951    118.728586     92.085252     89.965195   \n",
       "\n",
       "       mfcc_3_noise    mfcc_4_std   mfcc_4_mean  mfcc_4_noise    mfcc_5_std  \\\n",
       "count  30947.000000  30947.000000  30947.000000  30947.000000  30947.000000   \n",
       "mean      30.067026     29.524960     29.485805     29.035557     28.434550   \n",
       "std       15.237449     15.111426     15.600575     15.600374     15.252728   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       16.509955     16.142753     15.170072     14.981445     14.189170   \n",
       "50%       30.586093     30.338455     30.395567     30.146264     29.760050   \n",
       "75%       42.094875     41.359002     41.674235     40.984961     40.346104   \n",
       "max       89.935857    113.100970    118.224343    120.085079    113.077150   \n",
       "\n",
       "           ...         sflat_mean   sflat_noise     sroll_std    sroll_mean  \\\n",
       "count      ...       3.094700e+04  3.094700e+04  3.094700e+04  30947.000000   \n",
       "mean       ...      -1.535995e-02 -1.984839e-02 -1.938723e-02     14.260070   \n",
       "std        ...       2.086369e-01  2.085811e-01  2.070859e-01     22.763022   \n",
       "min        ...      -7.723873e-01 -7.458212e-01 -7.421038e-01      3.736712   \n",
       "25%        ...      -1.610912e-01 -1.659554e-01 -1.654091e-01      9.477854   \n",
       "50%        ...      -4.367921e-09 -5.277997e-09 -8.137921e-09     11.984384   \n",
       "75%        ...       1.205989e-01  1.163689e-01  1.146088e-01     15.742905   \n",
       "max        ...       8.057657e-01  8.572066e-01  7.961318e-01   2206.362673   \n",
       "\n",
       "        sroll_noise      rmse_std     rmse_mean    rmse_noise      h_target  \\\n",
       "count  30947.000000  30947.000000  30947.000000  30947.000000  30947.000000   \n",
       "mean      25.679845      5.237762     22.727680      4.911355      0.676673   \n",
       "std       35.058448     15.400834     17.316189      3.410737      0.467754   \n",
       "min        6.454405      1.436722      0.000000      0.510542      0.000000   \n",
       "25%       17.833900      3.478282     14.893102      2.640077      0.000000   \n",
       "50%       21.852503      4.507795     18.785621      4.292363      1.000000   \n",
       "75%       27.626522      5.601991     25.275695      6.459832      1.000000   \n",
       "max     5031.091987   2444.047253    620.895529    156.366775      1.000000   \n",
       "\n",
       "             target  \n",
       "count  30947.000000  \n",
       "mean      24.927586  \n",
       "std       14.392002  \n",
       "min        0.000000  \n",
       "25%       12.000000  \n",
       "50%       25.000000  \n",
       "75%       38.000000  \n",
       "max       49.000000  \n",
       "\n",
       "[8 rows x 131 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target','h_target'], axis=1)\n",
    "y = df['target']\n",
    "yy = df['h_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, yy = balanced_subsample(X, yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "### No Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "components = list(range(5,129))\n",
    "\n",
    "clf = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    SVC(probability=True, max_iter=10000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(clf, \n",
    "                        X, yy, \n",
    "                        cv=5, \n",
    "                        scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
    "                        n_jobs=5\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281.682517</td>\n",
       "      <td>46.834159</td>\n",
       "      <td>0.601648</td>\n",
       "      <td>0.599347</td>\n",
       "      <td>0.602830</td>\n",
       "      <td>0.595904</td>\n",
       "      <td>0.651087</td>\n",
       "      <td>0.625750</td>\n",
       "      <td>0.620462</td>\n",
       "      <td>0.629354</td>\n",
       "      <td>0.611819</td>\n",
       "      <td>0.675767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273.520171</td>\n",
       "      <td>40.129122</td>\n",
       "      <td>0.643428</td>\n",
       "      <td>0.632122</td>\n",
       "      <td>0.652822</td>\n",
       "      <td>0.612694</td>\n",
       "      <td>0.685663</td>\n",
       "      <td>0.628107</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.628589</td>\n",
       "      <td>0.626234</td>\n",
       "      <td>0.677486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290.074479</td>\n",
       "      <td>47.012586</td>\n",
       "      <td>0.596202</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.592682</td>\n",
       "      <td>0.615192</td>\n",
       "      <td>0.639396</td>\n",
       "      <td>0.622986</td>\n",
       "      <td>0.615345</td>\n",
       "      <td>0.628073</td>\n",
       "      <td>0.603123</td>\n",
       "      <td>0.677787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>335.720415</td>\n",
       "      <td>52.067996</td>\n",
       "      <td>0.617441</td>\n",
       "      <td>0.618870</td>\n",
       "      <td>0.616567</td>\n",
       "      <td>0.621189</td>\n",
       "      <td>0.663389</td>\n",
       "      <td>0.624360</td>\n",
       "      <td>0.618981</td>\n",
       "      <td>0.627973</td>\n",
       "      <td>0.610244</td>\n",
       "      <td>0.674102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275.085119</td>\n",
       "      <td>40.719429</td>\n",
       "      <td>0.625687</td>\n",
       "      <td>0.614910</td>\n",
       "      <td>0.633139</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.685752</td>\n",
       "      <td>0.626359</td>\n",
       "      <td>0.619272</td>\n",
       "      <td>0.631244</td>\n",
       "      <td>0.607745</td>\n",
       "      <td>0.674115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time  test_accuracy   test_f1  test_precision  \\\n",
       "0  281.682517   46.834159       0.601648  0.599347        0.602830   \n",
       "1  273.520171   40.129122       0.643428  0.632122        0.652822   \n",
       "2  290.074479   47.012586       0.596202  0.603727        0.592682   \n",
       "3  335.720415   52.067996       0.617441  0.618870        0.616567   \n",
       "4  275.085119   40.719429       0.625687  0.614910        0.633139   \n",
       "\n",
       "   test_recall  test_roc_auc  train_accuracy  train_f1  train_precision  \\\n",
       "0     0.595904      0.651087        0.625750  0.620462         0.629354   \n",
       "1     0.612694      0.685663        0.628107  0.627409         0.628589   \n",
       "2     0.615192      0.639396        0.622986  0.615345         0.628073   \n",
       "3     0.621189      0.663389        0.624360  0.618981         0.627973   \n",
       "4     0.597701      0.685752        0.626359  0.619272         0.631244   \n",
       "\n",
       "   train_recall  train_roc_auc  \n",
       "0      0.611819       0.675767  \n",
       "1      0.626234       0.677486  \n",
       "2      0.603123       0.677787  \n",
       "3      0.610244       0.674102  \n",
       "4      0.607745       0.674115  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_stats = pd.DataFrame(scores)\n",
    "default_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time           291.216540\n",
       "score_time          45.352658\n",
       "test_accuracy        0.616881\n",
       "test_f1              0.613795\n",
       "test_precision       0.619608\n",
       "test_recall          0.608536\n",
       "test_roc_auc         0.665057\n",
       "train_accuracy       0.625512\n",
       "train_f1             0.620294\n",
       "train_precision      0.629047\n",
       "train_recall         0.611833\n",
       "train_roc_auc        0.675851\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_stats_red = default_stats.mean()\n",
    "default_stats_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time          291.216540\n",
       "test_roc_auc        0.665057\n",
       "test_accuracy       0.616881\n",
       "test_recall         0.608536\n",
       "test_precision      0.619608\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_stats_red = pd.Series(default_stats_red[\n",
    "    ['fit_time',\n",
    "     'test_roc_auc', \n",
    "     'test_accuracy', \n",
    "     'test_recall', \n",
    "     'test_precision']\n",
    "])\n",
    "default_stats_red.columns = ['mean_fit_time', 'mean_test_roc_auc', 'mean_test_accuracy', 'mean_test_recall', 'mean_test_precision']\n",
    "default_stats_red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('feat', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=10000, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=5,\n",
       "       param_grid={'feat__n_components': range(25, 100, 25)},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('feat', PCA(n_components=None)),\n",
    "    ('classify', SVC(probability=True, max_iter=10000))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'feat__n_components': range(25, 100, 25)\n",
    "}\n",
    "\n",
    "gridsrc = GridSearchCV(clf, \n",
    "                        cv=5, \n",
    "                        param_grid=params,\n",
    "                        scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
    "                        verbose=2,\n",
    "                        n_jobs=5,\n",
    "                        refit=False\n",
    "                       )\n",
    "gridsrc.fit(X,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_train_precision</th>\n",
       "      <th>std_train_recall</th>\n",
       "      <th>std_train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83.655381</td>\n",
       "      <td>12.647235</td>\n",
       "      <td>0.604387</td>\n",
       "      <td>0.615820</td>\n",
       "      <td>0.598833</td>\n",
       "      <td>0.633920</td>\n",
       "      <td>0.646698</td>\n",
       "      <td>0.614994</td>\n",
       "      <td>0.623478</td>\n",
       "      <td>0.610081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015153</td>\n",
       "      <td>0.011767</td>\n",
       "      <td>0.016031</td>\n",
       "      <td>0.008653</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>0.003724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112.294402</td>\n",
       "      <td>19.418971</td>\n",
       "      <td>0.627224</td>\n",
       "      <td>0.623107</td>\n",
       "      <td>0.630453</td>\n",
       "      <td>0.616230</td>\n",
       "      <td>0.676703</td>\n",
       "      <td>0.639616</td>\n",
       "      <td>0.632681</td>\n",
       "      <td>0.645129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.007703</td>\n",
       "      <td>0.013937</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.001937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.044849</td>\n",
       "      <td>24.804808</td>\n",
       "      <td>0.626774</td>\n",
       "      <td>0.626103</td>\n",
       "      <td>0.627686</td>\n",
       "      <td>0.624825</td>\n",
       "      <td>0.677254</td>\n",
       "      <td>0.638942</td>\n",
       "      <td>0.635447</td>\n",
       "      <td>0.641677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013081</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>0.016094</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>0.013965</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.001296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_accuracy  mean_test_f1  \\\n",
       "0      83.655381        12.647235            0.604387      0.615820   \n",
       "1     112.294402        19.418971            0.627224      0.623107   \n",
       "2     150.044849        24.804808            0.626774      0.626103   \n",
       "\n",
       "   mean_test_precision  mean_test_recall  mean_test_roc_auc  \\\n",
       "0             0.598833          0.633920           0.646698   \n",
       "1             0.630453          0.616230           0.676703   \n",
       "2             0.627686          0.624825           0.677254   \n",
       "\n",
       "   mean_train_accuracy  mean_train_f1  mean_train_precision  \\\n",
       "0             0.614994       0.623478              0.610081   \n",
       "1             0.639616       0.632681              0.645129   \n",
       "2             0.638942       0.635447              0.641677   \n",
       "\n",
       "         ...          std_test_accuracy  std_test_f1 std_test_precision  \\\n",
       "0        ...                   0.015153     0.011767           0.016031   \n",
       "1        ...                   0.010583     0.007703           0.013937   \n",
       "2        ...                   0.013081     0.009715           0.016094   \n",
       "\n",
       "  std_test_recall  std_test_roc_auc  std_train_accuracy  std_train_f1  \\\n",
       "0        0.008653          0.016474            0.003445      0.006050   \n",
       "1        0.010711          0.011925            0.002264      0.004148   \n",
       "2        0.010720          0.013965            0.002297      0.003760   \n",
       "\n",
       "   std_train_precision  std_train_recall  std_train_roc_auc  \n",
       "0             0.004583          0.014336           0.003724  \n",
       "1             0.003839          0.009798           0.001937  \n",
       "2             0.003309          0.008430           0.001296  \n",
       "\n",
       "[3 rows x 81 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_stats = pd.DataFrame(gridsrc.cv_results_)\n",
    "pca_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time\n",
      "mean_score_time\n",
      "mean_test_accuracy\n",
      "mean_test_f1\n",
      "mean_test_precision\n",
      "mean_test_recall\n",
      "mean_test_roc_auc\n",
      "mean_train_accuracy\n",
      "mean_train_f1\n",
      "mean_train_precision\n",
      "mean_train_recall\n",
      "mean_train_roc_auc\n",
      "param_feat__n_components\n",
      "params\n",
      "rank_test_accuracy\n",
      "rank_test_f1\n",
      "rank_test_precision\n",
      "rank_test_recall\n",
      "rank_test_roc_auc\n",
      "split0_test_accuracy\n",
      "split0_test_f1\n",
      "split0_test_precision\n",
      "split0_test_recall\n",
      "split0_test_roc_auc\n",
      "split0_train_accuracy\n",
      "split0_train_f1\n",
      "split0_train_precision\n",
      "split0_train_recall\n",
      "split0_train_roc_auc\n",
      "split1_test_accuracy\n",
      "split1_test_f1\n",
      "split1_test_precision\n",
      "split1_test_recall\n",
      "split1_test_roc_auc\n",
      "split1_train_accuracy\n",
      "split1_train_f1\n",
      "split1_train_precision\n",
      "split1_train_recall\n",
      "split1_train_roc_auc\n",
      "split2_test_accuracy\n",
      "split2_test_f1\n",
      "split2_test_precision\n",
      "split2_test_recall\n",
      "split2_test_roc_auc\n",
      "split2_train_accuracy\n",
      "split2_train_f1\n",
      "split2_train_precision\n",
      "split2_train_recall\n",
      "split2_train_roc_auc\n",
      "split3_test_accuracy\n",
      "split3_test_f1\n",
      "split3_test_precision\n",
      "split3_test_recall\n",
      "split3_test_roc_auc\n",
      "split3_train_accuracy\n",
      "split3_train_f1\n",
      "split3_train_precision\n",
      "split3_train_recall\n",
      "split3_train_roc_auc\n",
      "split4_test_accuracy\n",
      "split4_test_f1\n",
      "split4_test_precision\n",
      "split4_test_recall\n",
      "split4_test_roc_auc\n",
      "split4_train_accuracy\n",
      "split4_train_f1\n",
      "split4_train_precision\n",
      "split4_train_recall\n",
      "split4_train_roc_auc\n",
      "std_fit_time\n",
      "std_score_time\n",
      "std_test_accuracy\n",
      "std_test_f1\n",
      "std_test_precision\n",
      "std_test_recall\n",
      "std_test_roc_auc\n",
      "std_train_accuracy\n",
      "std_train_f1\n",
      "std_train_precision\n",
      "std_train_recall\n",
      "std_train_roc_auc\n"
     ]
    }
   ],
   "source": [
    "for col in pca_stats.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_feat__n_components</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>150.044849</td>\n",
       "      <td>0.677254</td>\n",
       "      <td>0.626774</td>\n",
       "      <td>0.624825</td>\n",
       "      <td>0.627686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>112.294402</td>\n",
       "      <td>0.676703</td>\n",
       "      <td>0.627224</td>\n",
       "      <td>0.616230</td>\n",
       "      <td>0.630453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>83.655381</td>\n",
       "      <td>0.646698</td>\n",
       "      <td>0.604387</td>\n",
       "      <td>0.633920</td>\n",
       "      <td>0.598833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_feat__n_components  mean_fit_time  mean_test_roc_auc  \\\n",
       "2                       75     150.044849           0.677254   \n",
       "1                       50     112.294402           0.676703   \n",
       "0                       25      83.655381           0.646698   \n",
       "\n",
       "   mean_test_accuracy  mean_test_recall  mean_test_precision  \n",
       "2            0.626774          0.624825             0.627686  \n",
       "1            0.627224          0.616230             0.630453  \n",
       "0            0.604387          0.633920             0.598833  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_stats_red = pca_stats[\n",
    "    ['param_feat__n_components', \n",
    "     'mean_fit_time',\n",
    "     'mean_test_roc_auc', \n",
    "     'mean_test_accuracy', \n",
    "     'mean_test_recall', \n",
    "     'mean_test_precision']\n",
    "]\n",
    "\n",
    "pca_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision'],\n",
    "             ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed: 101.8min\n",
      "[Parallel(n_jobs=5)]: Done  60 out of  60 | elapsed: 202.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('feat', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=None, kernel='linear',\n",
       "     kernel_params=None, max_iter=None, n_components=None, n_jobs=5,\n",
       "     random_state=N..., max_iter=10000, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=5,\n",
       "       param_grid={'feat__kernel': ['poly', 'rbf', 'sigmoid', 'cosine'], 'feat__n_components': range(25, 100, 25)},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('feat', KernelPCA(n_components=None, n_jobs=5)),\n",
    "    ('classify', SVC(probability=True, max_iter=10000))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'feat__n_components': range(25, 100, 25),\n",
    "    'feat__kernel': ['poly', 'rbf', 'sigmoid', 'cosine']\n",
    "}\n",
    "\n",
    "gridsrc = GridSearchCV(\n",
    "                clf,\n",
    "                scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'], \n",
    "                cv=5,\n",
    "                refit=False,\n",
    "                param_grid = params,\n",
    "                verbose=2,\n",
    "                n_jobs=5\n",
    ")\n",
    "\n",
    "gridsrc.fit(X,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_train_precision</th>\n",
       "      <th>std_train_recall</th>\n",
       "      <th>std_train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619.595322</td>\n",
       "      <td>27.696823</td>\n",
       "      <td>0.580652</td>\n",
       "      <td>0.582894</td>\n",
       "      <td>0.580925</td>\n",
       "      <td>0.585649</td>\n",
       "      <td>0.607082</td>\n",
       "      <td>0.581589</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>0.580975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020805</td>\n",
       "      <td>0.013528</td>\n",
       "      <td>0.024267</td>\n",
       "      <td>0.015047</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.005026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>641.505239</td>\n",
       "      <td>36.921804</td>\n",
       "      <td>0.580152</td>\n",
       "      <td>0.584168</td>\n",
       "      <td>0.579861</td>\n",
       "      <td>0.589346</td>\n",
       "      <td>0.603018</td>\n",
       "      <td>0.579990</td>\n",
       "      <td>0.583467</td>\n",
       "      <td>0.578715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021156</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.013366</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.005214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>597.600831</td>\n",
       "      <td>44.712577</td>\n",
       "      <td>0.577503</td>\n",
       "      <td>0.584506</td>\n",
       "      <td>0.575944</td>\n",
       "      <td>0.593944</td>\n",
       "      <td>0.598347</td>\n",
       "      <td>0.578141</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.575910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020421</td>\n",
       "      <td>0.013121</td>\n",
       "      <td>0.022791</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.025033</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.005351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>618.543224</td>\n",
       "      <td>64.303539</td>\n",
       "      <td>0.575805</td>\n",
       "      <td>0.584118</td>\n",
       "      <td>0.574037</td>\n",
       "      <td>0.595343</td>\n",
       "      <td>0.597758</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.584547</td>\n",
       "      <td>0.574063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020936</td>\n",
       "      <td>0.012413</td>\n",
       "      <td>0.023662</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>0.024868</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.005547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>753.098903</td>\n",
       "      <td>71.975377</td>\n",
       "      <td>0.574006</td>\n",
       "      <td>0.587875</td>\n",
       "      <td>0.570353</td>\n",
       "      <td>0.607236</td>\n",
       "      <td>0.595435</td>\n",
       "      <td>0.575118</td>\n",
       "      <td>0.588160</td>\n",
       "      <td>0.570692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.012511</td>\n",
       "      <td>0.022479</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>0.024977</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.005498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_accuracy  mean_test_f1  \\\n",
       "0     619.595322        27.696823            0.580652      0.582894   \n",
       "1     641.505239        36.921804            0.580152      0.584168   \n",
       "2     597.600831        44.712577            0.577503      0.584506   \n",
       "3     618.543224        64.303539            0.575805      0.584118   \n",
       "4     753.098903        71.975377            0.574006      0.587875   \n",
       "\n",
       "   mean_test_precision  mean_test_recall  mean_test_roc_auc  \\\n",
       "0             0.580925          0.585649           0.607082   \n",
       "1             0.579861          0.589346           0.603018   \n",
       "2             0.575944          0.593944           0.598347   \n",
       "3             0.574037          0.595343           0.597758   \n",
       "4             0.570353          0.607236           0.595435   \n",
       "\n",
       "   mean_train_accuracy  mean_train_f1  mean_train_precision  \\\n",
       "0             0.581589       0.583276              0.580975   \n",
       "1             0.579990       0.583467              0.578715   \n",
       "2             0.578141       0.584399              0.575910   \n",
       "3             0.576792       0.584547              0.574063   \n",
       "4             0.575118       0.588160              0.570692   \n",
       "\n",
       "         ...          std_test_accuracy  std_test_f1 std_test_precision  \\\n",
       "0        ...                   0.020805     0.013528           0.024267   \n",
       "1        ...                   0.021156     0.012759           0.024644   \n",
       "2        ...                   0.020421     0.013121           0.022791   \n",
       "3        ...                   0.020936     0.012413           0.023662   \n",
       "4        ...                   0.020653     0.012511           0.022479   \n",
       "\n",
       "  std_test_recall std_test_roc_auc  std_train_accuracy  std_train_f1  \\\n",
       "0        0.015047         0.024493            0.004237      0.002933   \n",
       "1        0.013366         0.024777            0.004499      0.003338   \n",
       "2        0.012720         0.025033            0.004652      0.002624   \n",
       "3        0.013180         0.024868            0.004136      0.002779   \n",
       "4        0.013487         0.024977            0.004530      0.002564   \n",
       "\n",
       "   std_train_precision  std_train_recall  std_train_roc_auc  \n",
       "0             0.004859          0.003166           0.005026  \n",
       "1             0.004988          0.003380           0.005214  \n",
       "2             0.005245          0.000638           0.005351  \n",
       "3             0.004523          0.002447           0.005547  \n",
       "4             0.004930          0.001826           0.005498  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpca_stats = pd.DataFrame(gridsrc.cv_results_)\n",
    "kpca_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_feat__n_components</th>\n",
       "      <th>param_feat__kernel</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>cosine</td>\n",
       "      <td>739.063274</td>\n",
       "      <td>0.612045</td>\n",
       "      <td>0.578803</td>\n",
       "      <td>0.604237</td>\n",
       "      <td>0.576057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>cosine</td>\n",
       "      <td>828.904075</td>\n",
       "      <td>0.608082</td>\n",
       "      <td>0.576554</td>\n",
       "      <td>0.606636</td>\n",
       "      <td>0.573270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>poly</td>\n",
       "      <td>619.595322</td>\n",
       "      <td>0.607082</td>\n",
       "      <td>0.580652</td>\n",
       "      <td>0.585649</td>\n",
       "      <td>0.580925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>poly</td>\n",
       "      <td>641.505239</td>\n",
       "      <td>0.603018</td>\n",
       "      <td>0.580152</td>\n",
       "      <td>0.589346</td>\n",
       "      <td>0.579861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75</td>\n",
       "      <td>cosine</td>\n",
       "      <td>895.126515</td>\n",
       "      <td>0.602535</td>\n",
       "      <td>0.574006</td>\n",
       "      <td>0.611933</td>\n",
       "      <td>0.569704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>poly</td>\n",
       "      <td>597.600831</td>\n",
       "      <td>0.598347</td>\n",
       "      <td>0.577503</td>\n",
       "      <td>0.593944</td>\n",
       "      <td>0.575944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>rbf</td>\n",
       "      <td>618.543224</td>\n",
       "      <td>0.597758</td>\n",
       "      <td>0.575805</td>\n",
       "      <td>0.595343</td>\n",
       "      <td>0.574037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>rbf</td>\n",
       "      <td>753.098903</td>\n",
       "      <td>0.595435</td>\n",
       "      <td>0.574006</td>\n",
       "      <td>0.607236</td>\n",
       "      <td>0.570353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75</td>\n",
       "      <td>rbf</td>\n",
       "      <td>863.327263</td>\n",
       "      <td>0.593739</td>\n",
       "      <td>0.579602</td>\n",
       "      <td>0.568859</td>\n",
       "      <td>0.583291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>836.314673</td>\n",
       "      <td>0.593566</td>\n",
       "      <td>0.582600</td>\n",
       "      <td>0.547571</td>\n",
       "      <td>0.589705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>799.724622</td>\n",
       "      <td>0.593201</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.543674</td>\n",
       "      <td>0.590475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>611.667871</td>\n",
       "      <td>0.591187</td>\n",
       "      <td>0.581201</td>\n",
       "      <td>0.528183</td>\n",
       "      <td>0.591837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_feat__n_components param_feat__kernel  mean_fit_time  \\\n",
       "9                        25             cosine     739.063274   \n",
       "10                       50             cosine     828.904075   \n",
       "0                        25               poly     619.595322   \n",
       "1                        50               poly     641.505239   \n",
       "11                       75             cosine     895.126515   \n",
       "2                        75               poly     597.600831   \n",
       "3                        25                rbf     618.543224   \n",
       "4                        50                rbf     753.098903   \n",
       "5                        75                rbf     863.327263   \n",
       "8                        75            sigmoid     836.314673   \n",
       "7                        50            sigmoid     799.724622   \n",
       "6                        25            sigmoid     611.667871   \n",
       "\n",
       "    mean_test_roc_auc  mean_test_accuracy  mean_test_recall  \\\n",
       "9            0.612045            0.578803          0.604237   \n",
       "10           0.608082            0.576554          0.606636   \n",
       "0            0.607082            0.580652          0.585649   \n",
       "1            0.603018            0.580152          0.589346   \n",
       "11           0.602535            0.574006          0.611933   \n",
       "2            0.598347            0.577503          0.593944   \n",
       "3            0.597758            0.575805          0.595343   \n",
       "4            0.595435            0.574006          0.607236   \n",
       "5            0.593739            0.579602          0.568859   \n",
       "8            0.593566            0.582600          0.547571   \n",
       "7            0.593201            0.582550          0.543674   \n",
       "6            0.591187            0.581201          0.528183   \n",
       "\n",
       "    mean_test_precision  \n",
       "9              0.576057  \n",
       "10             0.573270  \n",
       "0              0.580925  \n",
       "1              0.579861  \n",
       "11             0.569704  \n",
       "2              0.575944  \n",
       "3              0.574037  \n",
       "4              0.570353  \n",
       "5              0.583291  \n",
       "8              0.589705  \n",
       "7              0.590475  \n",
       "6              0.591837  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpca_stats_red = kpca_stats[\n",
    "    ['param_feat__n_components',\n",
    "     'param_feat__kernel',\n",
    "     'mean_fit_time',\n",
    "     'mean_test_roc_auc', \n",
    "     'mean_test_accuracy', \n",
    "     'mean_test_recall', \n",
    "     'mean_test_precision']\n",
    "]\n",
    "\n",
    "kpca_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision'],\n",
    "             ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  30 out of  30 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('feat', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)), ('classify', SVC(C=1.0, cache_size=200, class_w... max_iter=10000, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=5,\n",
       "       param_grid={'feat__n_components': range(25, 100, 25), 'feat__solver': ['svd', 'eigen']},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('feat', LinearDiscriminantAnalysis(n_components=None)),\n",
    "    ('classify', SVC(probability=True, max_iter=10000))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'feat__n_components': range(25, 100, 25),\n",
    "    'feat__solver': ['svd', 'eigen']\n",
    "}\n",
    "\n",
    "gridsrc = GridSearchCV(\n",
    "                clf,\n",
    "                scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'], \n",
    "                cv=5,\n",
    "                refit=False,\n",
    "                param_grid = params,\n",
    "                verbose=2,\n",
    "                n_jobs=5\n",
    ")\n",
    "\n",
    "gridsrc.fit(X,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_train_precision</th>\n",
       "      <th>std_train_recall</th>\n",
       "      <th>std_train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.015051</td>\n",
       "      <td>6.605457</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>0.641555</td>\n",
       "      <td>0.645920</td>\n",
       "      <td>0.637418</td>\n",
       "      <td>0.680388</td>\n",
       "      <td>0.658417</td>\n",
       "      <td>0.653584</td>\n",
       "      <td>0.663029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.003197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.273077</td>\n",
       "      <td>7.137635</td>\n",
       "      <td>0.644763</td>\n",
       "      <td>0.646123</td>\n",
       "      <td>0.643672</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>0.658105</td>\n",
       "      <td>0.657164</td>\n",
       "      <td>0.658974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.008328</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.627933</td>\n",
       "      <td>6.384449</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>0.641555</td>\n",
       "      <td>0.645920</td>\n",
       "      <td>0.637418</td>\n",
       "      <td>0.680388</td>\n",
       "      <td>0.658417</td>\n",
       "      <td>0.653584</td>\n",
       "      <td>0.663029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.003197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.375954</td>\n",
       "      <td>7.224759</td>\n",
       "      <td>0.644763</td>\n",
       "      <td>0.646123</td>\n",
       "      <td>0.643672</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>0.658105</td>\n",
       "      <td>0.657164</td>\n",
       "      <td>0.658974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.008328</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.827396</td>\n",
       "      <td>6.000429</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>0.641555</td>\n",
       "      <td>0.645920</td>\n",
       "      <td>0.637418</td>\n",
       "      <td>0.680388</td>\n",
       "      <td>0.658417</td>\n",
       "      <td>0.653584</td>\n",
       "      <td>0.663029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.003197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_accuracy  mean_test_f1  \\\n",
       "0      43.015051         6.605457            0.643914      0.641555   \n",
       "1      46.273077         7.137635            0.644763      0.646123   \n",
       "2      45.627933         6.384449            0.643914      0.641555   \n",
       "3      50.375954         7.224759            0.644763      0.646123   \n",
       "4      44.827396         6.000429            0.643914      0.641555   \n",
       "\n",
       "   mean_test_precision  mean_test_recall  mean_test_roc_auc  \\\n",
       "0             0.645920          0.637418           0.680388   \n",
       "1             0.643672          0.648611           0.694582   \n",
       "2             0.645920          0.637418           0.680388   \n",
       "3             0.643672          0.648611           0.694582   \n",
       "4             0.645920          0.637418           0.680388   \n",
       "\n",
       "   mean_train_accuracy  mean_train_f1  mean_train_precision  \\\n",
       "0             0.658417       0.653584              0.663029   \n",
       "1             0.658105       0.657164              0.658974   \n",
       "2             0.658417       0.653584              0.663029   \n",
       "3             0.658105       0.657164              0.658974   \n",
       "4             0.658417       0.653584              0.663029   \n",
       "\n",
       "         ...          std_test_accuracy  std_test_f1 std_test_precision  \\\n",
       "0        ...                   0.007122     0.007496           0.008462   \n",
       "1        ...                   0.007961     0.007872           0.008036   \n",
       "2        ...                   0.007122     0.007496           0.008462   \n",
       "3        ...                   0.007961     0.007872           0.008036   \n",
       "4        ...                   0.007122     0.007496           0.008462   \n",
       "\n",
       "  std_test_recall std_test_roc_auc  std_train_accuracy  std_train_f1  \\\n",
       "0        0.012109         0.002385            0.001808      0.004060   \n",
       "1        0.008446         0.006551            0.001785      0.003769   \n",
       "2        0.012109         0.002385            0.001808      0.004060   \n",
       "3        0.008446         0.006551            0.001785      0.003769   \n",
       "4        0.012109         0.002385            0.001808      0.004060   \n",
       "\n",
       "   std_train_precision  std_train_recall  std_train_roc_auc  \n",
       "0             0.004755          0.011367           0.003197  \n",
       "1             0.002006          0.008328           0.000431  \n",
       "2             0.004755          0.011367           0.003197  \n",
       "3             0.002006          0.008328           0.000431  \n",
       "4             0.004755          0.011367           0.003197  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_stats = pd.DataFrame(gridsrc.cv_results_)\n",
    "lda_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_feat__n_components</th>\n",
       "      <th>param_feat__solver</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>eigen</td>\n",
       "      <td>46.273077</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>0.644763</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.643672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>eigen</td>\n",
       "      <td>50.375954</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>0.644763</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.643672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75</td>\n",
       "      <td>eigen</td>\n",
       "      <td>44.913033</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>0.644763</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.643672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>svd</td>\n",
       "      <td>43.015051</td>\n",
       "      <td>0.680388</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>0.637418</td>\n",
       "      <td>0.645920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>svd</td>\n",
       "      <td>45.627933</td>\n",
       "      <td>0.680388</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>0.637418</td>\n",
       "      <td>0.645920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>svd</td>\n",
       "      <td>44.827396</td>\n",
       "      <td>0.680388</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>0.637418</td>\n",
       "      <td>0.645920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_feat__n_components param_feat__solver  mean_fit_time  \\\n",
       "1                       25              eigen      46.273077   \n",
       "3                       50              eigen      50.375954   \n",
       "5                       75              eigen      44.913033   \n",
       "0                       25                svd      43.015051   \n",
       "2                       50                svd      45.627933   \n",
       "4                       75                svd      44.827396   \n",
       "\n",
       "   mean_test_roc_auc  mean_test_accuracy  mean_test_recall  \\\n",
       "1           0.694582            0.644763          0.648611   \n",
       "3           0.694582            0.644763          0.648611   \n",
       "5           0.694582            0.644763          0.648611   \n",
       "0           0.680388            0.643914          0.637418   \n",
       "2           0.680388            0.643914          0.637418   \n",
       "4           0.680388            0.643914          0.637418   \n",
       "\n",
       "   mean_test_precision  \n",
       "1             0.643672  \n",
       "3             0.643672  \n",
       "5             0.643672  \n",
       "0             0.645920  \n",
       "2             0.645920  \n",
       "4             0.645920  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_stats_red = lda_stats[\n",
    "    ['param_feat__n_components',\n",
    "     'param_feat__solver',\n",
    "     'mean_fit_time',\n",
    "     'mean_test_roc_auc', \n",
    "     'mean_test_accuracy', \n",
    "     'mean_test_recall', \n",
    "     'mean_test_precision']\n",
    "]\n",
    "\n",
    "lda_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision'],\n",
    "             ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=5)]: Done  60 out of  60 | elapsed: 52.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('feat', SelectKBest(k=None, score_func=<function f_classif at 0x7fca4dcc7a60>)), ('classify', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=10000, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=5,\n",
       "       param_grid={'feat__score_func': [<function chi2 at 0x7fca4dcc7b70>, <function mutual_info_classif at 0x7fca4d7ed950>, <function f_classif at 0x7fca4dcc7a60>], 'feat__k': range(25, 125, 25)},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, f_classif\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('feat', SelectKBest(k=None)),\n",
    "    ('classify', SVC(probability=True, max_iter=10000))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'feat__k': range(25, 125, 25),\n",
    "    'feat__score_func': [chi2, mutual_info_classif, f_classif]\n",
    "}\n",
    "\n",
    "gridsrc = GridSearchCV(\n",
    "                clf,\n",
    "                scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'], \n",
    "                cv=5,\n",
    "                refit=False,\n",
    "                param_grid = params,\n",
    "                verbose=2,\n",
    "                n_jobs=5\n",
    ")\n",
    "\n",
    "gridsrc.fit(X,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_train_precision</th>\n",
       "      <th>std_train_recall</th>\n",
       "      <th>std_train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.393754</td>\n",
       "      <td>12.443814</td>\n",
       "      <td>0.590546</td>\n",
       "      <td>0.579461</td>\n",
       "      <td>0.596575</td>\n",
       "      <td>0.563962</td>\n",
       "      <td>0.628939</td>\n",
       "      <td>0.596355</td>\n",
       "      <td>0.583015</td>\n",
       "      <td>0.602958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019281</td>\n",
       "      <td>0.014483</td>\n",
       "      <td>0.024063</td>\n",
       "      <td>0.016325</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.017214</td>\n",
       "      <td>0.004250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.924781</td>\n",
       "      <td>12.386046</td>\n",
       "      <td>0.602838</td>\n",
       "      <td>0.605154</td>\n",
       "      <td>0.601936</td>\n",
       "      <td>0.608835</td>\n",
       "      <td>0.641839</td>\n",
       "      <td>0.610022</td>\n",
       "      <td>0.611352</td>\n",
       "      <td>0.609228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>0.013239</td>\n",
       "      <td>0.015498</td>\n",
       "      <td>0.019415</td>\n",
       "      <td>0.017402</td>\n",
       "      <td>0.006590</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.006214</td>\n",
       "      <td>0.017630</td>\n",
       "      <td>0.008520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.226459</td>\n",
       "      <td>12.421222</td>\n",
       "      <td>0.589246</td>\n",
       "      <td>0.584030</td>\n",
       "      <td>0.591883</td>\n",
       "      <td>0.576754</td>\n",
       "      <td>0.629568</td>\n",
       "      <td>0.598941</td>\n",
       "      <td>0.590078</td>\n",
       "      <td>0.603384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.017163</td>\n",
       "      <td>0.019938</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.023084</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.003061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.794332</td>\n",
       "      <td>18.696415</td>\n",
       "      <td>0.628523</td>\n",
       "      <td>0.630692</td>\n",
       "      <td>0.627358</td>\n",
       "      <td>0.634319</td>\n",
       "      <td>0.676529</td>\n",
       "      <td>0.637930</td>\n",
       "      <td>0.636972</td>\n",
       "      <td>0.638680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010420</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.012951</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.010131</td>\n",
       "      <td>0.000738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128.079404</td>\n",
       "      <td>19.111710</td>\n",
       "      <td>0.612982</td>\n",
       "      <td>0.614112</td>\n",
       "      <td>0.612754</td>\n",
       "      <td>0.615930</td>\n",
       "      <td>0.656268</td>\n",
       "      <td>0.618279</td>\n",
       "      <td>0.617050</td>\n",
       "      <td>0.618973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012059</td>\n",
       "      <td>0.009688</td>\n",
       "      <td>0.014782</td>\n",
       "      <td>0.015680</td>\n",
       "      <td>0.016803</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.018639</td>\n",
       "      <td>0.008623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_accuracy  mean_test_f1  \\\n",
       "0      85.393754        12.443814            0.590546      0.579461   \n",
       "1      98.924781        12.386046            0.602838      0.605154   \n",
       "2      86.226459        12.421222            0.589246      0.584030   \n",
       "3     111.794332        18.696415            0.628523      0.630692   \n",
       "4     128.079404        19.111710            0.612982      0.614112   \n",
       "\n",
       "   mean_test_precision  mean_test_recall  mean_test_roc_auc  \\\n",
       "0             0.596575          0.563962           0.628939   \n",
       "1             0.601936          0.608835           0.641839   \n",
       "2             0.591883          0.576754           0.629568   \n",
       "3             0.627358          0.634319           0.676529   \n",
       "4             0.612754          0.615930           0.656268   \n",
       "\n",
       "   mean_train_accuracy  mean_train_f1  mean_train_precision  \\\n",
       "0             0.596355       0.583015              0.602958   \n",
       "1             0.610022       0.611352              0.609228   \n",
       "2             0.598941       0.590078              0.603384   \n",
       "3             0.637930       0.636972              0.638680   \n",
       "4             0.618279       0.617050              0.618973   \n",
       "\n",
       "         ...          std_test_accuracy  std_test_f1 std_test_precision  \\\n",
       "0        ...                   0.019281     0.014483           0.024063   \n",
       "1        ...                   0.013760     0.013239           0.015498   \n",
       "2        ...                   0.018134     0.017163           0.019938   \n",
       "3        ...                   0.010420     0.007584           0.012951   \n",
       "4        ...                   0.012059     0.009688           0.014782   \n",
       "\n",
       "  std_test_recall std_test_roc_auc  std_train_accuracy  std_train_f1  \\\n",
       "0        0.016325         0.022738            0.003608      0.008638   \n",
       "1        0.019415         0.017402            0.006590      0.010047   \n",
       "2        0.020600         0.023084            0.003213      0.011194   \n",
       "3        0.010194         0.009988            0.001636      0.004123   \n",
       "4        0.015680         0.016803            0.006251      0.010364   \n",
       "\n",
       "   std_train_precision  std_train_recall  std_train_roc_auc  \n",
       "0             0.004346          0.017214           0.004250  \n",
       "1             0.006214          0.017630           0.008520  \n",
       "2             0.003203          0.023295           0.003061  \n",
       "3             0.002913          0.010131           0.000738  \n",
       "4             0.005587          0.018639           0.008623  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest_stats = pd.DataFrame(gridsrc.cv_results_)\n",
    "kbest_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_feat__k</th>\n",
       "      <th>param_feat__score_func</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>111.794332</td>\n",
       "      <td>0.676529</td>\n",
       "      <td>0.628523</td>\n",
       "      <td>0.634319</td>\n",
       "      <td>0.627358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>149.449979</td>\n",
       "      <td>0.672380</td>\n",
       "      <td>0.624875</td>\n",
       "      <td>0.626124</td>\n",
       "      <td>0.624947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75</td>\n",
       "      <td>&lt;function f_classif at 0x7fca4dcc7a60&gt;</td>\n",
       "      <td>151.731154</td>\n",
       "      <td>0.670860</td>\n",
       "      <td>0.624925</td>\n",
       "      <td>0.627923</td>\n",
       "      <td>0.624546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>210.641218</td>\n",
       "      <td>0.669232</td>\n",
       "      <td>0.620927</td>\n",
       "      <td>0.616230</td>\n",
       "      <td>0.622608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function f_classif at 0x7fca4dcc7a60&gt;</td>\n",
       "      <td>112.421140</td>\n",
       "      <td>0.668148</td>\n",
       "      <td>0.622077</td>\n",
       "      <td>0.630222</td>\n",
       "      <td>0.620289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>&lt;function f_classif at 0x7fca4dcc7a60&gt;</td>\n",
       "      <td>196.531623</td>\n",
       "      <td>0.667758</td>\n",
       "      <td>0.620328</td>\n",
       "      <td>0.619928</td>\n",
       "      <td>0.621112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x7fca4d7ed950&gt;</td>\n",
       "      <td>167.731177</td>\n",
       "      <td>0.661701</td>\n",
       "      <td>0.615431</td>\n",
       "      <td>0.617130</td>\n",
       "      <td>0.615493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x7fca4d7ed950&gt;</td>\n",
       "      <td>211.974515</td>\n",
       "      <td>0.658856</td>\n",
       "      <td>0.614032</td>\n",
       "      <td>0.611933</td>\n",
       "      <td>0.615028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x7fca4d7ed950&gt;</td>\n",
       "      <td>128.079404</td>\n",
       "      <td>0.656268</td>\n",
       "      <td>0.612982</td>\n",
       "      <td>0.615930</td>\n",
       "      <td>0.612754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x7fca4d7ed950&gt;</td>\n",
       "      <td>98.924781</td>\n",
       "      <td>0.641839</td>\n",
       "      <td>0.602838</td>\n",
       "      <td>0.608835</td>\n",
       "      <td>0.601936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>&lt;function f_classif at 0x7fca4dcc7a60&gt;</td>\n",
       "      <td>86.226459</td>\n",
       "      <td>0.629568</td>\n",
       "      <td>0.589246</td>\n",
       "      <td>0.576754</td>\n",
       "      <td>0.591883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>85.393754</td>\n",
       "      <td>0.628939</td>\n",
       "      <td>0.590546</td>\n",
       "      <td>0.563962</td>\n",
       "      <td>0.596575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_feat__k                            param_feat__score_func  \\\n",
       "3             50                 <function chi2 at 0x7fca4dcc7b70>   \n",
       "6             75                 <function chi2 at 0x7fca4dcc7b70>   \n",
       "8             75            <function f_classif at 0x7fca4dcc7a60>   \n",
       "9            100                 <function chi2 at 0x7fca4dcc7b70>   \n",
       "5             50            <function f_classif at 0x7fca4dcc7a60>   \n",
       "11           100            <function f_classif at 0x7fca4dcc7a60>   \n",
       "7             75  <function mutual_info_classif at 0x7fca4d7ed950>   \n",
       "10           100  <function mutual_info_classif at 0x7fca4d7ed950>   \n",
       "4             50  <function mutual_info_classif at 0x7fca4d7ed950>   \n",
       "1             25  <function mutual_info_classif at 0x7fca4d7ed950>   \n",
       "2             25            <function f_classif at 0x7fca4dcc7a60>   \n",
       "0             25                 <function chi2 at 0x7fca4dcc7b70>   \n",
       "\n",
       "    mean_fit_time  mean_test_roc_auc  mean_test_accuracy  mean_test_recall  \\\n",
       "3      111.794332           0.676529            0.628523          0.634319   \n",
       "6      149.449979           0.672380            0.624875          0.626124   \n",
       "8      151.731154           0.670860            0.624925          0.627923   \n",
       "9      210.641218           0.669232            0.620927          0.616230   \n",
       "5      112.421140           0.668148            0.622077          0.630222   \n",
       "11     196.531623           0.667758            0.620328          0.619928   \n",
       "7      167.731177           0.661701            0.615431          0.617130   \n",
       "10     211.974515           0.658856            0.614032          0.611933   \n",
       "4      128.079404           0.656268            0.612982          0.615930   \n",
       "1       98.924781           0.641839            0.602838          0.608835   \n",
       "2       86.226459           0.629568            0.589246          0.576754   \n",
       "0       85.393754           0.628939            0.590546          0.563962   \n",
       "\n",
       "    mean_test_precision  \n",
       "3              0.627358  \n",
       "6              0.624947  \n",
       "8              0.624546  \n",
       "9              0.622608  \n",
       "5              0.620289  \n",
       "11             0.621112  \n",
       "7              0.615493  \n",
       "10             0.615028  \n",
       "4              0.612754  \n",
       "1              0.601936  \n",
       "2              0.591883  \n",
       "0              0.596575  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest_stats_red = kbest_stats[\n",
    "    ['param_feat__k',\n",
    "     'param_feat__score_func',\n",
    "     'mean_fit_time',\n",
    "     'mean_test_roc_auc', \n",
    "     'mean_test_accuracy', \n",
    "     'mean_test_recall', \n",
    "     'mean_test_precision']\n",
    "]\n",
    "\n",
    "kbest_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision'],\n",
    "             ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=5)]: Done  75 out of  75 | elapsed: 18.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('feat_sel', SelectKBest(k=50, score_func=<function f_classif at 0x7fca4dcc7a60>)), ('feat_red', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001..., max_iter=10000, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=5,\n",
       "       param_grid={'feat_red__solver': ['eigen'], 'feat_sel__k': range(50, 100, 10), 'feat_sel__score_func': [<function chi2 at 0x7fca4dcc7b70>], 'feat_red__n_components': range(10, 25, 5)},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('feat_sel', SelectKBest(k=50)),\n",
    "    ('feat_red', LinearDiscriminantAnalysis(n_components=None)),\n",
    "    ('classify', SVC(probability=True, max_iter=10000))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'feat_sel__k': range(50, 100, 10),\n",
    "    'feat_sel__score_func': [chi2],\n",
    "    'feat_red__n_components': range(10, 25, 5),\n",
    "    'feat_red__solver': ['eigen']\n",
    "}\n",
    "\n",
    "gridsrc = GridSearchCV(\n",
    "                clf,\n",
    "                scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'], \n",
    "                cv=5,\n",
    "                refit=False,\n",
    "                param_grid = params,\n",
    "                verbose=2,\n",
    "                n_jobs=5\n",
    ")\n",
    "\n",
    "gridsrc.fit(X,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_train_precision</th>\n",
       "      <th>std_train_recall</th>\n",
       "      <th>std_train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.924432</td>\n",
       "      <td>5.832423</td>\n",
       "      <td>0.644663</td>\n",
       "      <td>0.645969</td>\n",
       "      <td>0.643682</td>\n",
       "      <td>0.648311</td>\n",
       "      <td>0.690861</td>\n",
       "      <td>0.649910</td>\n",
       "      <td>0.650085</td>\n",
       "      <td>0.649843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>0.001582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.541990</td>\n",
       "      <td>5.884764</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>0.643432</td>\n",
       "      <td>0.644453</td>\n",
       "      <td>0.642614</td>\n",
       "      <td>0.690633</td>\n",
       "      <td>0.652621</td>\n",
       "      <td>0.650394</td>\n",
       "      <td>0.654598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.404535</td>\n",
       "      <td>5.518799</td>\n",
       "      <td>0.644363</td>\n",
       "      <td>0.644390</td>\n",
       "      <td>0.644463</td>\n",
       "      <td>0.644413</td>\n",
       "      <td>0.690758</td>\n",
       "      <td>0.654857</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.007468</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.367818</td>\n",
       "      <td>5.543276</td>\n",
       "      <td>0.645213</td>\n",
       "      <td>0.643931</td>\n",
       "      <td>0.646332</td>\n",
       "      <td>0.641715</td>\n",
       "      <td>0.691473</td>\n",
       "      <td>0.655457</td>\n",
       "      <td>0.652525</td>\n",
       "      <td>0.658128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.011014</td>\n",
       "      <td>0.005420</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.001444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.000950</td>\n",
       "      <td>5.522272</td>\n",
       "      <td>0.644963</td>\n",
       "      <td>0.644039</td>\n",
       "      <td>0.645756</td>\n",
       "      <td>0.642415</td>\n",
       "      <td>0.692817</td>\n",
       "      <td>0.655469</td>\n",
       "      <td>0.652258</td>\n",
       "      <td>0.658386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>0.008738</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_accuracy  mean_test_f1  \\\n",
       "0      45.924432         5.832423            0.644663      0.645969   \n",
       "1      45.541990         5.884764            0.643914      0.643432   \n",
       "2      45.404535         5.518799            0.644363      0.644390   \n",
       "3      45.367818         5.543276            0.645213      0.643931   \n",
       "4      45.000950         5.522272            0.644963      0.644039   \n",
       "\n",
       "   mean_test_precision  mean_test_recall  mean_test_roc_auc  \\\n",
       "0             0.643682          0.648311           0.690861   \n",
       "1             0.644453          0.642614           0.690633   \n",
       "2             0.644463          0.644413           0.690758   \n",
       "3             0.646332          0.641715           0.691473   \n",
       "4             0.645756          0.642415           0.692817   \n",
       "\n",
       "   mean_train_accuracy  mean_train_f1  mean_train_precision  \\\n",
       "0             0.649910       0.650085              0.649843   \n",
       "1             0.652621       0.650394              0.654598   \n",
       "2             0.654857       0.652826              0.656693   \n",
       "3             0.655457       0.652525              0.658128   \n",
       "4             0.655469       0.652258              0.658386   \n",
       "\n",
       "         ...          std_test_accuracy  std_test_f1 std_test_precision  \\\n",
       "0        ...                   0.005723     0.004303           0.006920   \n",
       "1        ...                   0.005192     0.004530           0.007872   \n",
       "2        ...                   0.005500     0.003766           0.007468   \n",
       "3        ...                   0.003643     0.004753           0.005508   \n",
       "4        ...                   0.004872     0.005251           0.005789   \n",
       "\n",
       "  std_test_recall std_test_roc_auc std_train_accuracy std_train_f1  \\\n",
       "0        0.003657         0.004903           0.002558     0.001521   \n",
       "1        0.010342         0.004717           0.000855     0.002374   \n",
       "2        0.005846         0.005489           0.000787     0.002213   \n",
       "3        0.011014         0.005420           0.001179     0.002008   \n",
       "4        0.008738         0.005566           0.001547     0.003307   \n",
       "\n",
       "   std_train_precision  std_train_recall  std_train_roc_auc  \n",
       "0             0.005093          0.006925           0.001582  \n",
       "1             0.001854          0.006054           0.000845  \n",
       "2             0.001349          0.005337           0.001167  \n",
       "3             0.001550          0.004372           0.001444  \n",
       "4             0.001367          0.006912           0.001543  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_stats = pd.DataFrame(gridsrc.cv_results_)\n",
    "comb_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'mean_score_time', 'mean_test_accuracy',\n",
       "       'mean_test_f1', 'mean_test_precision', 'mean_test_recall',\n",
       "       'mean_test_roc_auc', 'mean_train_accuracy', 'mean_train_f1',\n",
       "       'mean_train_precision', 'mean_train_recall', 'mean_train_roc_auc',\n",
       "       'param_feat_red__n_components', 'param_feat_red__solver',\n",
       "       'param_feat_sel__k', 'param_feat_sel__score_func', 'params',\n",
       "       'rank_test_accuracy', 'rank_test_f1', 'rank_test_precision',\n",
       "       'rank_test_recall', 'rank_test_roc_auc', 'split0_test_accuracy',\n",
       "       'split0_test_f1', 'split0_test_precision', 'split0_test_recall',\n",
       "       'split0_test_roc_auc', 'split0_train_accuracy', 'split0_train_f1',\n",
       "       'split0_train_precision', 'split0_train_recall', 'split0_train_roc_auc',\n",
       "       'split1_test_accuracy', 'split1_test_f1', 'split1_test_precision',\n",
       "       'split1_test_recall', 'split1_test_roc_auc', 'split1_train_accuracy',\n",
       "       'split1_train_f1', 'split1_train_precision', 'split1_train_recall',\n",
       "       'split1_train_roc_auc', 'split2_test_accuracy', 'split2_test_f1',\n",
       "       'split2_test_precision', 'split2_test_recall', 'split2_test_roc_auc',\n",
       "       'split2_train_accuracy', 'split2_train_f1', 'split2_train_precision',\n",
       "       'split2_train_recall', 'split2_train_roc_auc', 'split3_test_accuracy',\n",
       "       'split3_test_f1', 'split3_test_precision', 'split3_test_recall',\n",
       "       'split3_test_roc_auc', 'split3_train_accuracy', 'split3_train_f1',\n",
       "       'split3_train_precision', 'split3_train_recall', 'split3_train_roc_auc',\n",
       "       'split4_test_accuracy', 'split4_test_f1', 'split4_test_precision',\n",
       "       'split4_test_recall', 'split4_test_roc_auc', 'split4_train_accuracy',\n",
       "       'split4_train_f1', 'split4_train_precision', 'split4_train_recall',\n",
       "       'split4_train_roc_auc', 'std_fit_time', 'std_score_time',\n",
       "       'std_test_accuracy', 'std_test_f1', 'std_test_precision',\n",
       "       'std_test_recall', 'std_test_roc_auc', 'std_train_accuracy',\n",
       "       'std_train_f1', 'std_train_precision', 'std_train_recall',\n",
       "       'std_train_roc_auc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_feat_sel__k</th>\n",
       "      <th>param_feat_sel__score_func</th>\n",
       "      <th>param_feat_red__n_components</th>\n",
       "      <th>param_feat_red__solver</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.000950</td>\n",
       "      <td>0.692817</td>\n",
       "      <td>0.644963</td>\n",
       "      <td>0.642415</td>\n",
       "      <td>0.645756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>eigen</td>\n",
       "      <td>44.782609</td>\n",
       "      <td>0.692817</td>\n",
       "      <td>0.644963</td>\n",
       "      <td>0.642415</td>\n",
       "      <td>0.645756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.598498</td>\n",
       "      <td>0.692817</td>\n",
       "      <td>0.644963</td>\n",
       "      <td>0.642415</td>\n",
       "      <td>0.645756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.367818</td>\n",
       "      <td>0.691473</td>\n",
       "      <td>0.645213</td>\n",
       "      <td>0.641715</td>\n",
       "      <td>0.646332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.282259</td>\n",
       "      <td>0.691473</td>\n",
       "      <td>0.645213</td>\n",
       "      <td>0.641715</td>\n",
       "      <td>0.646332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.262764</td>\n",
       "      <td>0.691473</td>\n",
       "      <td>0.645213</td>\n",
       "      <td>0.641715</td>\n",
       "      <td>0.646332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.924432</td>\n",
       "      <td>0.690861</td>\n",
       "      <td>0.644663</td>\n",
       "      <td>0.648311</td>\n",
       "      <td>0.643682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.715398</td>\n",
       "      <td>0.690861</td>\n",
       "      <td>0.644663</td>\n",
       "      <td>0.648311</td>\n",
       "      <td>0.643682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.117728</td>\n",
       "      <td>0.690861</td>\n",
       "      <td>0.644663</td>\n",
       "      <td>0.648311</td>\n",
       "      <td>0.643682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.404535</td>\n",
       "      <td>0.690758</td>\n",
       "      <td>0.644363</td>\n",
       "      <td>0.644413</td>\n",
       "      <td>0.644463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>eigen</td>\n",
       "      <td>46.180180</td>\n",
       "      <td>0.690758</td>\n",
       "      <td>0.644363</td>\n",
       "      <td>0.644413</td>\n",
       "      <td>0.644463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>70</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.933145</td>\n",
       "      <td>0.690758</td>\n",
       "      <td>0.644363</td>\n",
       "      <td>0.644413</td>\n",
       "      <td>0.644463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.541990</td>\n",
       "      <td>0.690633</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>0.642614</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>eigen</td>\n",
       "      <td>46.076392</td>\n",
       "      <td>0.690633</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>0.642614</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>&lt;function chi2 at 0x7fca4dcc7b70&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>eigen</td>\n",
       "      <td>45.152384</td>\n",
       "      <td>0.690633</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>0.642614</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_feat_sel__k         param_feat_sel__score_func  \\\n",
       "4                 90  <function chi2 at 0x7fca4dcc7b70>   \n",
       "9                 90  <function chi2 at 0x7fca4dcc7b70>   \n",
       "14                90  <function chi2 at 0x7fca4dcc7b70>   \n",
       "3                 80  <function chi2 at 0x7fca4dcc7b70>   \n",
       "8                 80  <function chi2 at 0x7fca4dcc7b70>   \n",
       "13                80  <function chi2 at 0x7fca4dcc7b70>   \n",
       "0                 50  <function chi2 at 0x7fca4dcc7b70>   \n",
       "5                 50  <function chi2 at 0x7fca4dcc7b70>   \n",
       "10                50  <function chi2 at 0x7fca4dcc7b70>   \n",
       "2                 70  <function chi2 at 0x7fca4dcc7b70>   \n",
       "7                 70  <function chi2 at 0x7fca4dcc7b70>   \n",
       "12                70  <function chi2 at 0x7fca4dcc7b70>   \n",
       "1                 60  <function chi2 at 0x7fca4dcc7b70>   \n",
       "6                 60  <function chi2 at 0x7fca4dcc7b70>   \n",
       "11                60  <function chi2 at 0x7fca4dcc7b70>   \n",
       "\n",
       "   param_feat_red__n_components param_feat_red__solver  mean_fit_time  \\\n",
       "4                            10                  eigen      45.000950   \n",
       "9                            15                  eigen      44.782609   \n",
       "14                           20                  eigen      45.598498   \n",
       "3                            10                  eigen      45.367818   \n",
       "8                            15                  eigen      45.282259   \n",
       "13                           20                  eigen      45.262764   \n",
       "0                            10                  eigen      45.924432   \n",
       "5                            15                  eigen      45.715398   \n",
       "10                           20                  eigen      45.117728   \n",
       "2                            10                  eigen      45.404535   \n",
       "7                            15                  eigen      46.180180   \n",
       "12                           20                  eigen      45.933145   \n",
       "1                            10                  eigen      45.541990   \n",
       "6                            15                  eigen      46.076392   \n",
       "11                           20                  eigen      45.152384   \n",
       "\n",
       "    mean_test_roc_auc  mean_test_accuracy  mean_test_recall  \\\n",
       "4            0.692817            0.644963          0.642415   \n",
       "9            0.692817            0.644963          0.642415   \n",
       "14           0.692817            0.644963          0.642415   \n",
       "3            0.691473            0.645213          0.641715   \n",
       "8            0.691473            0.645213          0.641715   \n",
       "13           0.691473            0.645213          0.641715   \n",
       "0            0.690861            0.644663          0.648311   \n",
       "5            0.690861            0.644663          0.648311   \n",
       "10           0.690861            0.644663          0.648311   \n",
       "2            0.690758            0.644363          0.644413   \n",
       "7            0.690758            0.644363          0.644413   \n",
       "12           0.690758            0.644363          0.644413   \n",
       "1            0.690633            0.643914          0.642614   \n",
       "6            0.690633            0.643914          0.642614   \n",
       "11           0.690633            0.643914          0.642614   \n",
       "\n",
       "    mean_test_precision  \n",
       "4              0.645756  \n",
       "9              0.645756  \n",
       "14             0.645756  \n",
       "3              0.646332  \n",
       "8              0.646332  \n",
       "13             0.646332  \n",
       "0              0.643682  \n",
       "5              0.643682  \n",
       "10             0.643682  \n",
       "2              0.644463  \n",
       "7              0.644463  \n",
       "12             0.644463  \n",
       "1              0.644453  \n",
       "6              0.644453  \n",
       "11             0.644453  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_stats_red = comb_stats[\n",
    "    ['param_feat_sel__k',\n",
    "     'param_feat_sel__score_func',\n",
    "     'param_feat_red__n_components',\n",
    "     'param_feat_red__solver',\n",
    "     'mean_fit_time',\n",
    "     'mean_test_roc_auc', \n",
    "     'mean_test_accuracy', \n",
    "     'mean_test_recall', \n",
    "     'mean_test_precision']\n",
    "]\n",
    "\n",
    "comb_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision'],\n",
    "             ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stats_red['kind'] = 'None'\n",
    "default_stats_red['mean_test_roc_auc'] = default_stats_red['test_roc_auc']\n",
    "default_stats_red['mean_test_accuracy'] = default_stats_red['test_accuracy']\n",
    "default_stats_red['mean_test_recall'] = default_stats_red['test_recall']\n",
    "default_stats_red['mean_test_precision'] = default_stats_red['test_precision']\n",
    "\n",
    "pca=pca_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision'],\n",
    "             ascending=False)\n",
    "pca['kind'] = 'PCA'\n",
    "kpca=kpca_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision'],\n",
    "             ascending=False)\n",
    "kpca['kind'] = 'KPCA'\n",
    "lda=lda_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision'],\n",
    "             ascending=False)\n",
    "lda['kind'] = 'LDA'\n",
    "kbest=kbest_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision'],\n",
    "             ascending=False)\n",
    "kbest['kind'] = 'KBest'\n",
    "comb = comb_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision'],\n",
    "             ascending=False)\n",
    "comb['kind'] = 'combination'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative = pd.DataFrame([default_stats_red, pca.iloc[0], kpca.iloc[0], lda.iloc[0], kbest.iloc[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed 0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.665057</td>\n",
       "      <td>0.616881</td>\n",
       "      <td>0.608536</td>\n",
       "      <td>0.619608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA</td>\n",
       "      <td>0.677254</td>\n",
       "      <td>0.626774</td>\n",
       "      <td>0.624825</td>\n",
       "      <td>0.627686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KPCA</td>\n",
       "      <td>0.612045</td>\n",
       "      <td>0.578803</td>\n",
       "      <td>0.604237</td>\n",
       "      <td>0.576057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>0.644763</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.643672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KBest</td>\n",
       "      <td>0.676529</td>\n",
       "      <td>0.628523</td>\n",
       "      <td>0.634319</td>\n",
       "      <td>0.627358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            kind  mean_test_roc_auc  mean_test_accuracy  mean_test_recall  \\\n",
       "Unnamed 0   None           0.665057            0.616881          0.608536   \n",
       "2            PCA           0.677254            0.626774          0.624825   \n",
       "9           KPCA           0.612045            0.578803          0.604237   \n",
       "1            LDA           0.694582            0.644763          0.648611   \n",
       "3          KBest           0.676529            0.628523          0.634319   \n",
       "\n",
       "           mean_test_precision  \n",
       "Unnamed 0             0.619608  \n",
       "2                     0.627686  \n",
       "9                     0.576057  \n",
       "1                     0.643672  \n",
       "3                     0.627358  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative = comparative[['kind','mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision']]\n",
    "comparative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb355d37f0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparative.plot(x='kind',kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
