{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from classification_plots import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import Counter\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(9, 9), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (dropout): Dropout2d(p=0.2, inplace=False)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=50, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "BaseNet(\n",
      "  (conv1): Conv2d(1, 50, kernel_size=(9, 9), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(5, 5), stride=(4, 4), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(50, 100, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(5, 5), stride=(4, 4), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(100, 100, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(1, 20), stride=(1, 20), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self,):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 9)\n",
    "#         self.pool = nn.MaxPool2d(25, 17)\n",
    "#         self.norm = nn.BatchNorm2d(32)\n",
    "#         self.fc1 = nn.Linear(4608, 32)\n",
    "#         self.dropout = nn.Dropout2d(p=0.2)\n",
    "#         self.fc2 = nn.Linear(32, 32)\n",
    "#         self.fc3 = nn.Linear(32,50)\n",
    "#         self.softmax = nn.Softmax()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.norm(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.pool(x)\n",
    "#         x = x.view(x.shape[0], -1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc3(x)\n",
    "#         x = self.softmax(x)\n",
    "#         return x\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 9)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 5)\n",
    "        self.norm = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(7, 7)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.dropout = nn.Dropout2d(p=0.2)\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128,64)\n",
    "        self.fc4 = nn.Linear(64,50)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class BaseNet(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(BaseNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 50, 9)\n",
    "        self.pool1 = nn.MaxPool2d((5,5), (4,4))\n",
    "        self.conv2 = nn.Conv2d(50, 100, 7)\n",
    "        self.pool2 = nn.MaxPool2d((5,5), (4,4))\n",
    "        self.conv3 = nn.Conv2d(100, 100, 5)\n",
    "        self.pool3 = nn.MaxPool2d((1,20))\n",
    "        self.fc = nn.Linear(100, 50)\n",
    "#         self.dropout = nn.Dropout2d(p=0.2)\n",
    "#         self.fc2 = nn.Linear(32, 32)\n",
    "#         self.fc3 = nn.Linear(32,50)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         print(x.shape)\n",
    "        x = self.pool1(x)\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "#         print(x.shape)\n",
    "        x = self.pool2(x)\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.conv3(x)) \n",
    "#         print(x.shape)\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "net = Net()\n",
    "basenet = BaseNet()\n",
    "print(net)\n",
    "print(basenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n",
      "(1, 128, 431) ()\n"
     ]
    }
   ],
   "source": [
    "# load data:\n",
    "from PIL import Image\n",
    "import os \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class trainset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        root = \"./data2/\"\n",
    "        self.data_list = []\n",
    "        self.label_list = []\n",
    "        for root, dir, files in os.walk(\"./data2/\"):\n",
    "            for file in files:\n",
    "                if file.find('.npy')!= -1:\n",
    "                    self.data_list.append(os.path.join(root, file))\n",
    "                    self.label_list.append(int(root[13:]))\n",
    "        print(len(self.data_list), len(self.label_list))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        path = self.data_list[index]\n",
    "#         print(path)\n",
    "#         data = []\n",
    "#         label = []\n",
    "        data = np.load(path,allow_pickle = True)\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "#         data = np.asarray(Image.open(path))\n",
    "        label= self.label_list[index] \n",
    "#         print(data.shape)\n",
    "#         data = np.asarray(data)\n",
    "        label = np.asarray(label)\n",
    "        \n",
    "        return data, label\n",
    "dataloader = trainset()\n",
    "data,label = dataloader.__getitem__(5)\n",
    "# print(label.shape)\n",
    "print(data.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/netdissect/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 50]) torch.Size([128])\n",
      "torch.Size([128, 50]) torch.Size([128])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-98397d0b3786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/netdissect/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-3b7f8ae4b89e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/netdissect/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/netdissect/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/netdissect/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1655\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m     )\n\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "\n",
    "# model = BaseNet()\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "validation_split = .2\n",
    "random_seed= 42\n",
    "shuffle_dataset = True\n",
    "dataset_size = 2000\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "dataset  = trainset()\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=128, \n",
    "                                           sampler=train_sampler)\n",
    "valloader = torch.utils.data.DataLoader(dataset, batch_size=128,\n",
    "                                                sampler=valid_sampler)\n",
    "\n",
    "val_history = []\n",
    "val_loss_hist = []\n",
    "train_history = []\n",
    "train_loss_hist = []\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    \n",
    "########## Validation ###########\n",
    "    \n",
    "    count = 0\n",
    "    running_accuracy = 0\n",
    "    running_loss = 0\n",
    "    t1 = time.time()\n",
    "    for i, data in enumerate(valloader, 0):\n",
    "        count += 1\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        outputs = model(inputs)\n",
    "        print(outputs.shape, labels.shape)\n",
    "        val_loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        acc_val = torch.eq(preds, labels).float().mean()\n",
    "        running_accuracy += acc_val.item()\n",
    "        running_loss += val_loss.item()\n",
    "        \n",
    "    running_accuracy /= count\n",
    "    running_loss /= count\n",
    "    val_history.append(running_accuracy)\n",
    "    val_loss_hist.append(running_loss)\n",
    "    t2 = time.time()\n",
    "    print(\"===========Phase: Val============\")\n",
    "    print(\"Validation Time: {}\".format(t2 - t1))\n",
    "    print(\"Epoch: {}  val_loss: {}\".format(epoch, running_loss))\n",
    "    print(\"Epoch: {}  val_accuracy: {}\".format(epoch, running_accuracy))\n",
    "    \n",
    "######### Training ###########   \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "    training_accuracy = 0\n",
    "    t1 = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        count += 1\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        acc_train = torch.eq(preds, labels).float().mean()\n",
    "        running_accuracy += acc_train.item()\n",
    "        \n",
    "    running_accuracy /= count\n",
    "    running_loss /= count\n",
    "    train_history.append(running_accuracy)\n",
    "    train_loss_hist.append(running_loss)\n",
    "    t2 = time.time()\n",
    "    print(\"===========Phase: Train============\") \n",
    "    print(\"Training Time: {}\".format(t2 - t1))\n",
    "    print(\"Epoch: {}  train_loss: {}\".format(epoch, running_loss))\n",
    "    print(\"Epoch: {}  train_accuracy: {}\".format(epoch, running_accuracy))\n",
    "    print()\n",
    "        \n",
    "# # #             torch.save(net, 'toy_model.pt')\n",
    "        \n",
    "    \n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/netdissect/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net, './model_v0.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
