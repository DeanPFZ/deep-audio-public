{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/magenta/models/nsynth/wavenet/masked.py:115: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import pandas as pd\n",
    "from preprocess import Audio_Processor\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import enumerate_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000\n",
    "blocksize = int(SR/2)\n",
    "overlap = int(SR/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_db='../../ESC-50/'\n",
    "ps = Audio_Processor(path_to_db + 'audio/', sr=SR)\n",
    "dataset = pd.read_csv(path_to_db + 'meta/esc50.csv')\n",
    "classes = [None] * 50\n",
    "h_classes = ['Human & Animal', 'Interacting Materials']\n",
    "mapping = {\n",
    "    'dog': 0,\n",
    "    'rooster': 0,\n",
    "    'pig': 0,\n",
    "    'cow': 0,\n",
    "    'frog': 0,\n",
    "    'cat': 0,\n",
    "    'hen': 0,\n",
    "    'insects': 0,\n",
    "    'sheep': 0,\n",
    "    'crow': 0,\n",
    "    'rain': 1,\n",
    "    'sea_waves': 1,\n",
    "    'crackling_fire': 1,\n",
    "    'crickets': 0,\n",
    "    'chirping_birds': 0,\n",
    "    'water_drops': 1,\n",
    "    'wind': 1,\n",
    "    'pouring_water': 1,\n",
    "    'toilet_flush': 1,\n",
    "    'thunderstorm': 1,\n",
    "    'crying_baby': 0,\n",
    "    'sneezing': 0,\n",
    "    'clapping': 1,\n",
    "    'breathing': 0,\n",
    "    'coughing': 0,\n",
    "    'footsteps': 1,\n",
    "    'laughing': 0,\n",
    "    'brushing_teeth': 1,\n",
    "    'snoring': 0,\n",
    "    'drinking_sipping': 1,\n",
    "    'door_wood_knock': 1,\n",
    "    'mouse_click': 1,\n",
    "    'keyboard_typing': 1,\n",
    "    'door_wood_creaks': 1,\n",
    "    'can_opening': 1,\n",
    "    'washing_machine': 1,\n",
    "    'vacuum_cleaner': 1,\n",
    "    'clock_alarm': 1,\n",
    "    'clock_tick': 1,\n",
    "    'glass_breaking':1,\n",
    "    'helicopter': 1,\n",
    "    'chainsaw': 1,\n",
    "    'siren': 1,\n",
    "    'car_horn': 1,\n",
    "    'engine': 1,\n",
    "    'train': 1,\n",
    "    'church_bells': 1,\n",
    "    'airplane': 1,\n",
    "    'fireworks': 1,\n",
    "    'hand_saw': 1,\n",
    "}\n",
    "dataset['h_target'] = None\n",
    "for index, row in dataset.iterrows():\n",
    "    target = row['target']\n",
    "    classes[target] = row['category']\n",
    "    dataset.loc[index, 'h_target'] = mapping[row['category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Preprocessed Data\n",
    "We allow for previously preprocessed data to be retrieved for faster training turnaround. If the fold has been preprocessed, it is loaded but if not it is processed and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ps.preprocess_fold(dataset, \n",
    "                        kind='mfcc', \n",
    "                        blocksize=blocksize, \n",
    "                        overlap=overlap\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_2_std</th>\n",
       "      <th>mfcc_2_mean</th>\n",
       "      <th>mfcc_2_noise</th>\n",
       "      <th>mfcc_3_std</th>\n",
       "      <th>mfcc_3_mean</th>\n",
       "      <th>mfcc_3_noise</th>\n",
       "      <th>mfcc_4_std</th>\n",
       "      <th>mfcc_4_mean</th>\n",
       "      <th>mfcc_4_noise</th>\n",
       "      <th>mfcc_5_std</th>\n",
       "      <th>...</th>\n",
       "      <th>sflat_mean</th>\n",
       "      <th>sflat_noise</th>\n",
       "      <th>sroll_std</th>\n",
       "      <th>sroll_mean</th>\n",
       "      <th>sroll_noise</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_noise</th>\n",
       "      <th>h_target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.094700e+04</td>\n",
       "      <td>3.094700e+04</td>\n",
       "      <td>3.094700e+04</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "      <td>30947.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.719667</td>\n",
       "      <td>46.264479</td>\n",
       "      <td>38.909376</td>\n",
       "      <td>33.446607</td>\n",
       "      <td>30.420424</td>\n",
       "      <td>30.067026</td>\n",
       "      <td>29.524960</td>\n",
       "      <td>29.485805</td>\n",
       "      <td>29.035557</td>\n",
       "      <td>28.434550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.535995e-02</td>\n",
       "      <td>-1.984839e-02</td>\n",
       "      <td>-1.938723e-02</td>\n",
       "      <td>14.260070</td>\n",
       "      <td>25.679845</td>\n",
       "      <td>5.237762</td>\n",
       "      <td>22.727680</td>\n",
       "      <td>4.911355</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>24.927586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.473942</td>\n",
       "      <td>18.374510</td>\n",
       "      <td>17.074185</td>\n",
       "      <td>14.922491</td>\n",
       "      <td>14.885459</td>\n",
       "      <td>15.237449</td>\n",
       "      <td>15.111426</td>\n",
       "      <td>15.600575</td>\n",
       "      <td>15.600374</td>\n",
       "      <td>15.252728</td>\n",
       "      <td>...</td>\n",
       "      <td>2.086369e-01</td>\n",
       "      <td>2.085811e-01</td>\n",
       "      <td>2.070859e-01</td>\n",
       "      <td>22.763022</td>\n",
       "      <td>35.058448</td>\n",
       "      <td>15.400834</td>\n",
       "      <td>17.316189</td>\n",
       "      <td>3.410737</td>\n",
       "      <td>0.467754</td>\n",
       "      <td>14.392002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.723873e-01</td>\n",
       "      <td>-7.458212e-01</td>\n",
       "      <td>-7.421038e-01</td>\n",
       "      <td>3.736712</td>\n",
       "      <td>6.454405</td>\n",
       "      <td>1.436722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54.270596</td>\n",
       "      <td>34.628251</td>\n",
       "      <td>27.134954</td>\n",
       "      <td>22.152604</td>\n",
       "      <td>17.779317</td>\n",
       "      <td>16.509955</td>\n",
       "      <td>16.142753</td>\n",
       "      <td>15.170072</td>\n",
       "      <td>14.981445</td>\n",
       "      <td>14.189170</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610912e-01</td>\n",
       "      <td>-1.659554e-01</td>\n",
       "      <td>-1.654091e-01</td>\n",
       "      <td>9.477854</td>\n",
       "      <td>17.833900</td>\n",
       "      <td>3.478282</td>\n",
       "      <td>14.893102</td>\n",
       "      <td>2.640077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74.850493</td>\n",
       "      <td>46.716638</td>\n",
       "      <td>38.133677</td>\n",
       "      <td>33.581847</td>\n",
       "      <td>30.752174</td>\n",
       "      <td>30.586093</td>\n",
       "      <td>30.338455</td>\n",
       "      <td>30.395567</td>\n",
       "      <td>30.146264</td>\n",
       "      <td>29.760050</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.367921e-09</td>\n",
       "      <td>-5.277997e-09</td>\n",
       "      <td>-8.137921e-09</td>\n",
       "      <td>11.984384</td>\n",
       "      <td>21.852503</td>\n",
       "      <td>4.507795</td>\n",
       "      <td>18.785621</td>\n",
       "      <td>4.292363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>93.894152</td>\n",
       "      <td>58.166543</td>\n",
       "      <td>50.129512</td>\n",
       "      <td>44.366403</td>\n",
       "      <td>41.731754</td>\n",
       "      <td>42.094875</td>\n",
       "      <td>41.359002</td>\n",
       "      <td>41.674235</td>\n",
       "      <td>40.984961</td>\n",
       "      <td>40.346104</td>\n",
       "      <td>...</td>\n",
       "      <td>1.205989e-01</td>\n",
       "      <td>1.163689e-01</td>\n",
       "      <td>1.146088e-01</td>\n",
       "      <td>15.742905</td>\n",
       "      <td>27.626522</td>\n",
       "      <td>5.601991</td>\n",
       "      <td>25.275695</td>\n",
       "      <td>6.459832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>208.957500</td>\n",
       "      <td>123.849951</td>\n",
       "      <td>118.728586</td>\n",
       "      <td>92.085252</td>\n",
       "      <td>89.965195</td>\n",
       "      <td>89.935857</td>\n",
       "      <td>113.100970</td>\n",
       "      <td>118.224343</td>\n",
       "      <td>120.085079</td>\n",
       "      <td>113.077150</td>\n",
       "      <td>...</td>\n",
       "      <td>8.057657e-01</td>\n",
       "      <td>8.572066e-01</td>\n",
       "      <td>7.961318e-01</td>\n",
       "      <td>2206.362673</td>\n",
       "      <td>5031.091987</td>\n",
       "      <td>2444.047253</td>\n",
       "      <td>620.895529</td>\n",
       "      <td>156.366775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mfcc_2_std   mfcc_2_mean  mfcc_2_noise    mfcc_3_std   mfcc_3_mean  \\\n",
       "count  30947.000000  30947.000000  30947.000000  30947.000000  30947.000000   \n",
       "mean      73.719667     46.264479     38.909376     33.446607     30.420424   \n",
       "std       30.473942     18.374510     17.074185     14.922491     14.885459   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       54.270596     34.628251     27.134954     22.152604     17.779317   \n",
       "50%       74.850493     46.716638     38.133677     33.581847     30.752174   \n",
       "75%       93.894152     58.166543     50.129512     44.366403     41.731754   \n",
       "max      208.957500    123.849951    118.728586     92.085252     89.965195   \n",
       "\n",
       "       mfcc_3_noise    mfcc_4_std   mfcc_4_mean  mfcc_4_noise    mfcc_5_std  \\\n",
       "count  30947.000000  30947.000000  30947.000000  30947.000000  30947.000000   \n",
       "mean      30.067026     29.524960     29.485805     29.035557     28.434550   \n",
       "std       15.237449     15.111426     15.600575     15.600374     15.252728   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       16.509955     16.142753     15.170072     14.981445     14.189170   \n",
       "50%       30.586093     30.338455     30.395567     30.146264     29.760050   \n",
       "75%       42.094875     41.359002     41.674235     40.984961     40.346104   \n",
       "max       89.935857    113.100970    118.224343    120.085079    113.077150   \n",
       "\n",
       "           ...         sflat_mean   sflat_noise     sroll_std    sroll_mean  \\\n",
       "count      ...       3.094700e+04  3.094700e+04  3.094700e+04  30947.000000   \n",
       "mean       ...      -1.535995e-02 -1.984839e-02 -1.938723e-02     14.260070   \n",
       "std        ...       2.086369e-01  2.085811e-01  2.070859e-01     22.763022   \n",
       "min        ...      -7.723873e-01 -7.458212e-01 -7.421038e-01      3.736712   \n",
       "25%        ...      -1.610912e-01 -1.659554e-01 -1.654091e-01      9.477854   \n",
       "50%        ...      -4.367921e-09 -5.277997e-09 -8.137921e-09     11.984384   \n",
       "75%        ...       1.205989e-01  1.163689e-01  1.146088e-01     15.742905   \n",
       "max        ...       8.057657e-01  8.572066e-01  7.961318e-01   2206.362673   \n",
       "\n",
       "        sroll_noise      rmse_std     rmse_mean    rmse_noise      h_target  \\\n",
       "count  30947.000000  30947.000000  30947.000000  30947.000000  30947.000000   \n",
       "mean      25.679845      5.237762     22.727680      4.911355      0.676673   \n",
       "std       35.058448     15.400834     17.316189      3.410737      0.467754   \n",
       "min        6.454405      1.436722      0.000000      0.510542      0.000000   \n",
       "25%       17.833900      3.478282     14.893102      2.640077      0.000000   \n",
       "50%       21.852503      4.507795     18.785621      4.292363      1.000000   \n",
       "75%       27.626522      5.601991     25.275695      6.459832      1.000000   \n",
       "max     5031.091987   2444.047253    620.895529    156.366775      1.000000   \n",
       "\n",
       "             target  \n",
       "count  30947.000000  \n",
       "mean      24.927586  \n",
       "std       14.392002  \n",
       "min        0.000000  \n",
       "25%       12.000000  \n",
       "50%       25.000000  \n",
       "75%       38.000000  \n",
       "max       49.000000  \n",
       "\n",
       "[8 rows x 131 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target','h_target'], axis=1)\n",
    "y = df['target']\n",
    "yy = df['h_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "components = list(range(5,129))\n",
    "\n",
    "clf = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    SVC(max_iter=10000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_2_std</th>\n",
       "      <th>mfcc_2_mean</th>\n",
       "      <th>mfcc_2_noise</th>\n",
       "      <th>mfcc_3_std</th>\n",
       "      <th>mfcc_3_mean</th>\n",
       "      <th>mfcc_3_noise</th>\n",
       "      <th>mfcc_4_std</th>\n",
       "      <th>mfcc_4_mean</th>\n",
       "      <th>mfcc_4_noise</th>\n",
       "      <th>mfcc_5_std</th>\n",
       "      <th>...</th>\n",
       "      <th>sband_noise</th>\n",
       "      <th>sflat_std</th>\n",
       "      <th>sflat_mean</th>\n",
       "      <th>sflat_noise</th>\n",
       "      <th>sroll_std</th>\n",
       "      <th>sroll_mean</th>\n",
       "      <th>sroll_noise</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.566979</td>\n",
       "      <td>38.581673</td>\n",
       "      <td>23.175071</td>\n",
       "      <td>24.097116</td>\n",
       "      <td>14.293689</td>\n",
       "      <td>13.274004</td>\n",
       "      <td>9.751989</td>\n",
       "      <td>10.407591</td>\n",
       "      <td>10.445341</td>\n",
       "      <td>14.507037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249533</td>\n",
       "      <td>0.061410</td>\n",
       "      <td>-0.377001</td>\n",
       "      <td>0.093688</td>\n",
       "      <td>-0.244597</td>\n",
       "      <td>10.601514</td>\n",
       "      <td>20.214723</td>\n",
       "      <td>3.363856</td>\n",
       "      <td>18.003823</td>\n",
       "      <td>2.721278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.087553</td>\n",
       "      <td>42.385458</td>\n",
       "      <td>41.323666</td>\n",
       "      <td>42.334032</td>\n",
       "      <td>40.613859</td>\n",
       "      <td>46.154355</td>\n",
       "      <td>39.037316</td>\n",
       "      <td>36.109261</td>\n",
       "      <td>37.146942</td>\n",
       "      <td>63.689873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032375</td>\n",
       "      <td>-0.342203</td>\n",
       "      <td>-0.156344</td>\n",
       "      <td>0.210893</td>\n",
       "      <td>0.077557</td>\n",
       "      <td>19.903433</td>\n",
       "      <td>17.363853</td>\n",
       "      <td>5.242874</td>\n",
       "      <td>24.422219</td>\n",
       "      <td>6.690390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.118476</td>\n",
       "      <td>57.628917</td>\n",
       "      <td>43.107704</td>\n",
       "      <td>33.185557</td>\n",
       "      <td>54.154237</td>\n",
       "      <td>41.865626</td>\n",
       "      <td>36.732927</td>\n",
       "      <td>36.665436</td>\n",
       "      <td>51.713698</td>\n",
       "      <td>44.632980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>-0.019897</td>\n",
       "      <td>-0.069090</td>\n",
       "      <td>0.309464</td>\n",
       "      <td>0.088745</td>\n",
       "      <td>21.462776</td>\n",
       "      <td>17.886832</td>\n",
       "      <td>6.170742</td>\n",
       "      <td>20.789183</td>\n",
       "      <td>7.557844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.309076</td>\n",
       "      <td>62.498436</td>\n",
       "      <td>47.926910</td>\n",
       "      <td>36.613700</td>\n",
       "      <td>47.454525</td>\n",
       "      <td>44.457627</td>\n",
       "      <td>51.339283</td>\n",
       "      <td>34.410413</td>\n",
       "      <td>54.180220</td>\n",
       "      <td>48.870488</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135543</td>\n",
       "      <td>0.310175</td>\n",
       "      <td>-0.074617</td>\n",
       "      <td>-0.081635</td>\n",
       "      <td>-0.081316</td>\n",
       "      <td>21.383087</td>\n",
       "      <td>18.053033</td>\n",
       "      <td>6.724872</td>\n",
       "      <td>23.753132</td>\n",
       "      <td>8.544408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.369925</td>\n",
       "      <td>81.112403</td>\n",
       "      <td>42.470077</td>\n",
       "      <td>51.519435</td>\n",
       "      <td>48.344907</td>\n",
       "      <td>56.496477</td>\n",
       "      <td>67.439424</td>\n",
       "      <td>52.695489</td>\n",
       "      <td>56.905152</td>\n",
       "      <td>60.244643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360566</td>\n",
       "      <td>0.104958</td>\n",
       "      <td>-0.019650</td>\n",
       "      <td>0.133368</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>14.954617</td>\n",
       "      <td>18.298619</td>\n",
       "      <td>5.977200</td>\n",
       "      <td>28.201613</td>\n",
       "      <td>7.145342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mfcc_2_std  mfcc_2_mean  mfcc_2_noise  mfcc_3_std  mfcc_3_mean  \\\n",
       "0   29.566979    38.581673     23.175071   24.097116    14.293689   \n",
       "1   36.087553    42.385458     41.323666   42.334032    40.613859   \n",
       "2   41.118476    57.628917     43.107704   33.185557    54.154237   \n",
       "3   40.309076    62.498436     47.926910   36.613700    47.454525   \n",
       "4   47.369925    81.112403     42.470077   51.519435    48.344907   \n",
       "\n",
       "   mfcc_3_noise  mfcc_4_std  mfcc_4_mean  mfcc_4_noise  mfcc_5_std  \\\n",
       "0     13.274004    9.751989    10.407591     10.445341   14.507037   \n",
       "1     46.154355   39.037316    36.109261     37.146942   63.689873   \n",
       "2     41.865626   36.732927    36.665436     51.713698   44.632980   \n",
       "3     44.457627   51.339283    34.410413     54.180220   48.870488   \n",
       "4     56.496477   67.439424    52.695489     56.905152   60.244643   \n",
       "\n",
       "      ...      sband_noise  sflat_std  sflat_mean  sflat_noise  sroll_std  \\\n",
       "0     ...        -0.249533   0.061410   -0.377001     0.093688  -0.244597   \n",
       "1     ...        -0.032375  -0.342203   -0.156344     0.210893   0.077557   \n",
       "2     ...         0.010137  -0.019897   -0.069090     0.309464   0.088745   \n",
       "3     ...        -0.135543   0.310175   -0.074617    -0.081635  -0.081316   \n",
       "4     ...         0.360566   0.104958   -0.019650     0.133368   0.006017   \n",
       "\n",
       "   sroll_mean  sroll_noise  rmse_std  rmse_mean  rmse_noise  \n",
       "0   10.601514    20.214723  3.363856  18.003823    2.721278  \n",
       "1   19.903433    17.363853  5.242874  24.422219    6.690390  \n",
       "2   21.462776    17.886832  6.170742  20.789183    7.557844  \n",
       "3   21.383087    18.053033  6.724872  23.753132    8.544408  \n",
       "4   14.954617    18.298619  5.977200  28.201613    7.145342  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(clf, \n",
    "                        X, yy, \n",
    "                        cv=10, \n",
    "                        scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
    "                        n_jobs=-1\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153.168667</td>\n",
       "      <td>48.327644</td>\n",
       "      <td>0.676680</td>\n",
       "      <td>0.807166</td>\n",
       "      <td>0.676680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.676672</td>\n",
       "      <td>0.807161</td>\n",
       "      <td>0.676672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.691679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157.727300</td>\n",
       "      <td>50.688501</td>\n",
       "      <td>0.675929</td>\n",
       "      <td>0.806632</td>\n",
       "      <td>0.676366</td>\n",
       "      <td>0.999045</td>\n",
       "      <td>0.626220</td>\n",
       "      <td>0.676504</td>\n",
       "      <td>0.807042</td>\n",
       "      <td>0.676626</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.708445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156.395611</td>\n",
       "      <td>50.101707</td>\n",
       "      <td>0.676575</td>\n",
       "      <td>0.807092</td>\n",
       "      <td>0.676575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651732</td>\n",
       "      <td>0.676684</td>\n",
       "      <td>0.807169</td>\n",
       "      <td>0.676684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.699905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153.352353</td>\n",
       "      <td>48.380455</td>\n",
       "      <td>0.676575</td>\n",
       "      <td>0.807092</td>\n",
       "      <td>0.676575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.662400</td>\n",
       "      <td>0.676684</td>\n",
       "      <td>0.807169</td>\n",
       "      <td>0.676684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.696184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156.609837</td>\n",
       "      <td>50.256912</td>\n",
       "      <td>0.676575</td>\n",
       "      <td>0.807092</td>\n",
       "      <td>0.676575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665836</td>\n",
       "      <td>0.676684</td>\n",
       "      <td>0.807169</td>\n",
       "      <td>0.676684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time  test_accuracy   test_f1  test_precision  \\\n",
       "0  153.168667   48.327644       0.676680  0.807166        0.676680   \n",
       "1  157.727300   50.688501       0.675929  0.806632        0.676366   \n",
       "2  156.395611   50.101707       0.676575  0.807092        0.676575   \n",
       "3  153.352353   48.380455       0.676575  0.807092        0.676575   \n",
       "4  156.609837   50.256912       0.676575  0.807092        0.676575   \n",
       "\n",
       "   test_recall  test_roc_auc  train_accuracy  train_f1  train_precision  \\\n",
       "0     1.000000      0.684685        0.676672  0.807161         0.676672   \n",
       "1     0.999045      0.626220        0.676504  0.807042         0.676626   \n",
       "2     1.000000      0.651732        0.676684  0.807169         0.676684   \n",
       "3     1.000000      0.662400        0.676684  0.807169         0.676684   \n",
       "4     1.000000      0.665836        0.676684  0.807169         0.676684   \n",
       "\n",
       "   train_recall  train_roc_auc  \n",
       "0      1.000000       0.691679  \n",
       "1      0.999735       0.708445  \n",
       "2      1.000000       0.699905  \n",
       "3      1.000000       0.696184  \n",
       "4      1.000000       0.704070  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_stats = pd.DataFrame(scores)\n",
    "default_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time           154.922273\n",
       "score_time          49.385974\n",
       "test_accuracy        0.676576\n",
       "test_f1              0.807093\n",
       "test_precision       0.676642\n",
       "test_recall          0.999857\n",
       "test_roc_auc         0.673453\n",
       "train_accuracy       0.676655\n",
       "train_f1             0.807149\n",
       "train_precision      0.676667\n",
       "train_recall         0.999973\n",
       "train_roc_auc        0.694709\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_stats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 98 candidates, totalling 980 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed: 178.9min\n",
      "[Parallel(n_jobs=5)]: Done 638 tasks      | elapsed: 420.6min\n",
      "[Parallel(n_jobs=5)]: Done 980 out of 980 | elapsed: 869.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('feat', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=5,\n",
       "       param_grid={'feat__n_components': range(2, 100)},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('feat', PCA(n_components=None)),\n",
    "    ('classify', SVC())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'feat__n_components': range(2, 100)\n",
    "}\n",
    "\n",
    "gridsrc = GridSearchCV(clf, \n",
    "                        cv=10, \n",
    "                        param_grid=params,\n",
    "                        scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
    "                        verbose=2,\n",
    "                        n_jobs=5,\n",
    "                        refit=False\n",
    "                       )\n",
    "gridsrc.fit(X,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_train_precision</th>\n",
       "      <th>std_train_recall</th>\n",
       "      <th>std_train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.888287</td>\n",
       "      <td>7.162975</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.807162</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.539616</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.807162</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034501</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.079152</td>\n",
       "      <td>7.285370</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.807162</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.581242</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.807162</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038606</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.310083</td>\n",
       "      <td>7.434330</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.807162</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.566401</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.807162</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.278228</td>\n",
       "      <td>7.600838</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.807162</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569278</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.807162</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027687</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.810922</td>\n",
       "      <td>7.769433</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.807162</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578046</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.807162</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021658</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_accuracy  mean_test_f1  \\\n",
       "0      18.888287         7.162975            0.676673      0.807162   \n",
       "1      27.079152         7.285370            0.676673      0.807162   \n",
       "2      26.310083         7.434330            0.676673      0.807162   \n",
       "3      28.278228         7.600838            0.676673      0.807162   \n",
       "4      32.810922         7.769433            0.676673      0.807162   \n",
       "\n",
       "   mean_test_precision  mean_test_recall  mean_test_roc_auc  \\\n",
       "0             0.676673               1.0           0.539616   \n",
       "1             0.676673               1.0           0.581242   \n",
       "2             0.676673               1.0           0.566401   \n",
       "3             0.676673               1.0           0.569278   \n",
       "4             0.676673               1.0           0.578046   \n",
       "\n",
       "   mean_train_accuracy  mean_train_f1  mean_train_precision  \\\n",
       "0             0.676673       0.807162              0.676673   \n",
       "1             0.676673       0.807162              0.676673   \n",
       "2             0.676673       0.807162              0.676673   \n",
       "3             0.676673       0.807162              0.676673   \n",
       "4             0.676673       0.807162              0.676673   \n",
       "\n",
       "         ...          std_test_accuracy  std_test_f1 std_test_precision  \\\n",
       "0        ...                   0.000103     0.000073           0.000103   \n",
       "1        ...                   0.000103     0.000073           0.000103   \n",
       "2        ...                   0.000103     0.000073           0.000103   \n",
       "3        ...                   0.000103     0.000073           0.000103   \n",
       "4        ...                   0.000103     0.000073           0.000103   \n",
       "\n",
       "  std_test_recall  std_test_roc_auc  std_train_accuracy  std_train_f1  \\\n",
       "0             0.0          0.034501            0.000011      0.000008   \n",
       "1             0.0          0.038606            0.000011      0.000008   \n",
       "2             0.0          0.019630            0.000011      0.000008   \n",
       "3             0.0          0.027687            0.000011      0.000008   \n",
       "4             0.0          0.021658            0.000011      0.000008   \n",
       "\n",
       "   std_train_precision  std_train_recall  std_train_roc_auc  \n",
       "0             0.000011               0.0           0.026233  \n",
       "1             0.000011               0.0           0.020248  \n",
       "2             0.000011               0.0           0.023998  \n",
       "3             0.000011               0.0           0.016723  \n",
       "4             0.000011               0.0           0.012554  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_stats = pd.DataFrame(gridsrc.cv_results_)\n",
    "pca_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time\n",
      "mean_score_time\n",
      "mean_test_accuracy\n",
      "mean_test_f1\n",
      "mean_test_precision\n",
      "mean_test_recall\n",
      "mean_test_roc_auc\n",
      "mean_train_accuracy\n",
      "mean_train_f1\n",
      "mean_train_precision\n",
      "mean_train_recall\n",
      "mean_train_roc_auc\n",
      "param_feat__n_components\n",
      "params\n",
      "rank_test_accuracy\n",
      "rank_test_f1\n",
      "rank_test_precision\n",
      "rank_test_recall\n",
      "rank_test_roc_auc\n",
      "split0_test_accuracy\n",
      "split0_test_f1\n",
      "split0_test_precision\n",
      "split0_test_recall\n",
      "split0_test_roc_auc\n",
      "split0_train_accuracy\n",
      "split0_train_f1\n",
      "split0_train_precision\n",
      "split0_train_recall\n",
      "split0_train_roc_auc\n",
      "split1_test_accuracy\n",
      "split1_test_f1\n",
      "split1_test_precision\n",
      "split1_test_recall\n",
      "split1_test_roc_auc\n",
      "split1_train_accuracy\n",
      "split1_train_f1\n",
      "split1_train_precision\n",
      "split1_train_recall\n",
      "split1_train_roc_auc\n",
      "split2_test_accuracy\n",
      "split2_test_f1\n",
      "split2_test_precision\n",
      "split2_test_recall\n",
      "split2_test_roc_auc\n",
      "split2_train_accuracy\n",
      "split2_train_f1\n",
      "split2_train_precision\n",
      "split2_train_recall\n",
      "split2_train_roc_auc\n",
      "split3_test_accuracy\n",
      "split3_test_f1\n",
      "split3_test_precision\n",
      "split3_test_recall\n",
      "split3_test_roc_auc\n",
      "split3_train_accuracy\n",
      "split3_train_f1\n",
      "split3_train_precision\n",
      "split3_train_recall\n",
      "split3_train_roc_auc\n",
      "split4_test_accuracy\n",
      "split4_test_f1\n",
      "split4_test_precision\n",
      "split4_test_recall\n",
      "split4_test_roc_auc\n",
      "split4_train_accuracy\n",
      "split4_train_f1\n",
      "split4_train_precision\n",
      "split4_train_recall\n",
      "split4_train_roc_auc\n",
      "split5_test_accuracy\n",
      "split5_test_f1\n",
      "split5_test_precision\n",
      "split5_test_recall\n",
      "split5_test_roc_auc\n",
      "split5_train_accuracy\n",
      "split5_train_f1\n",
      "split5_train_precision\n",
      "split5_train_recall\n",
      "split5_train_roc_auc\n",
      "split6_test_accuracy\n",
      "split6_test_f1\n",
      "split6_test_precision\n",
      "split6_test_recall\n",
      "split6_test_roc_auc\n",
      "split6_train_accuracy\n",
      "split6_train_f1\n",
      "split6_train_precision\n",
      "split6_train_recall\n",
      "split6_train_roc_auc\n",
      "split7_test_accuracy\n",
      "split7_test_f1\n",
      "split7_test_precision\n",
      "split7_test_recall\n",
      "split7_test_roc_auc\n",
      "split7_train_accuracy\n",
      "split7_train_f1\n",
      "split7_train_precision\n",
      "split7_train_recall\n",
      "split7_train_roc_auc\n",
      "split8_test_accuracy\n",
      "split8_test_f1\n",
      "split8_test_precision\n",
      "split8_test_recall\n",
      "split8_test_roc_auc\n",
      "split8_train_accuracy\n",
      "split8_train_f1\n",
      "split8_train_precision\n",
      "split8_train_recall\n",
      "split8_train_roc_auc\n",
      "split9_test_accuracy\n",
      "split9_test_f1\n",
      "split9_test_precision\n",
      "split9_test_recall\n",
      "split9_test_roc_auc\n",
      "split9_train_accuracy\n",
      "split9_train_f1\n",
      "split9_train_precision\n",
      "split9_train_recall\n",
      "split9_train_roc_auc\n",
      "std_fit_time\n",
      "std_score_time\n",
      "std_test_accuracy\n",
      "std_test_f1\n",
      "std_test_precision\n",
      "std_test_recall\n",
      "std_test_roc_auc\n",
      "std_train_accuracy\n",
      "std_train_f1\n",
      "std_train_precision\n",
      "std_train_recall\n",
      "std_train_roc_auc\n"
     ]
    }
   ],
   "source": [
    "for col in pca_stats.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_feat__n_components</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>72</td>\n",
       "      <td>0.698478</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>79</td>\n",
       "      <td>0.698231</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>82</td>\n",
       "      <td>0.698171</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>81</td>\n",
       "      <td>0.698121</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>70</td>\n",
       "      <td>0.698076</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>71</td>\n",
       "      <td>0.698025</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>75</td>\n",
       "      <td>0.697909</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>76</td>\n",
       "      <td>0.697888</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>73</td>\n",
       "      <td>0.697884</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>78</td>\n",
       "      <td>0.697812</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>83</td>\n",
       "      <td>0.697728</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>84</td>\n",
       "      <td>0.697664</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>87</td>\n",
       "      <td>0.697631</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>74</td>\n",
       "      <td>0.697613</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>77</td>\n",
       "      <td>0.697594</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>85</td>\n",
       "      <td>0.697593</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>69</td>\n",
       "      <td>0.697561</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>80</td>\n",
       "      <td>0.697510</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>86</td>\n",
       "      <td>0.697446</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>67</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>95</td>\n",
       "      <td>0.697232</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>90</td>\n",
       "      <td>0.697223</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>68</td>\n",
       "      <td>0.697146</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>89</td>\n",
       "      <td>0.697078</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>60</td>\n",
       "      <td>0.697053</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>63</td>\n",
       "      <td>0.697045</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>66</td>\n",
       "      <td>0.697034</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>94</td>\n",
       "      <td>0.697014</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>92</td>\n",
       "      <td>0.696935</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>88</td>\n",
       "      <td>0.696925</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>0.659064</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>0.657752</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>0.657370</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>0.655892</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0.655233</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>0.655221</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0.652606</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.652480</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>0.651955</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.651200</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.648319</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.642424</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.631095</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.627677</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.618030</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.617714</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.617313</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.617095</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.611608</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.610604</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.605429</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.599658</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.599009</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.596688</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.581511</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.581242</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.578046</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.569278</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.566401</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.539616</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_feat__n_components  mean_test_roc_auc  mean_test_accuracy  \\\n",
       "70                       72           0.698478            0.676673   \n",
       "77                       79           0.698231            0.676673   \n",
       "80                       82           0.698171            0.676673   \n",
       "79                       81           0.698121            0.676673   \n",
       "68                       70           0.698076            0.676673   \n",
       "69                       71           0.698025            0.676673   \n",
       "73                       75           0.697909            0.676673   \n",
       "74                       76           0.697888            0.676673   \n",
       "71                       73           0.697884            0.676673   \n",
       "76                       78           0.697812            0.676673   \n",
       "81                       83           0.697728            0.676673   \n",
       "82                       84           0.697664            0.676673   \n",
       "85                       87           0.697631            0.676673   \n",
       "72                       74           0.697613            0.676673   \n",
       "75                       77           0.697594            0.676673   \n",
       "83                       85           0.697593            0.676673   \n",
       "67                       69           0.697561            0.676673   \n",
       "78                       80           0.697510            0.676673   \n",
       "84                       86           0.697446            0.676673   \n",
       "65                       67           0.697400            0.676673   \n",
       "93                       95           0.697232            0.676673   \n",
       "88                       90           0.697223            0.676673   \n",
       "66                       68           0.697146            0.676673   \n",
       "87                       89           0.697078            0.676673   \n",
       "58                       60           0.697053            0.676673   \n",
       "61                       63           0.697045            0.676673   \n",
       "64                       66           0.697034            0.676673   \n",
       "92                       94           0.697014            0.676673   \n",
       "90                       92           0.696935            0.676673   \n",
       "86                       88           0.696925            0.676673   \n",
       "..                      ...                ...                 ...   \n",
       "30                       32           0.659064            0.676673   \n",
       "28                       30           0.657752            0.676673   \n",
       "27                       29           0.657370            0.676673   \n",
       "25                       27           0.655892            0.676673   \n",
       "24                       26           0.655233            0.676673   \n",
       "26                       28           0.655221            0.676673   \n",
       "22                       24           0.652606            0.676673   \n",
       "21                       23           0.652480            0.676673   \n",
       "23                       25           0.651955            0.676673   \n",
       "20                       22           0.651200            0.676673   \n",
       "19                       21           0.648319            0.676673   \n",
       "18                       20           0.642424            0.676673   \n",
       "17                       19           0.631095            0.676673   \n",
       "16                       18           0.627677            0.676673   \n",
       "14                       16           0.618030            0.676673   \n",
       "15                       17           0.617714            0.676673   \n",
       "12                       14           0.617313            0.676673   \n",
       "13                       15           0.617095            0.676673   \n",
       "11                       13           0.611608            0.676673   \n",
       "10                       12           0.610604            0.676673   \n",
       "9                        11           0.605429            0.676673   \n",
       "6                         8           0.599658            0.676673   \n",
       "8                        10           0.599009            0.676673   \n",
       "7                         9           0.596688            0.676673   \n",
       "5                         7           0.581511            0.676673   \n",
       "1                         3           0.581242            0.676673   \n",
       "4                         6           0.578046            0.676673   \n",
       "3                         5           0.569278            0.676673   \n",
       "2                         4           0.566401            0.676673   \n",
       "0                         2           0.539616            0.676673   \n",
       "\n",
       "    mean_test_recall  mean_test_precision  \n",
       "70               1.0             0.676673  \n",
       "77               1.0             0.676673  \n",
       "80               1.0             0.676673  \n",
       "79               1.0             0.676673  \n",
       "68               1.0             0.676673  \n",
       "69               1.0             0.676673  \n",
       "73               1.0             0.676673  \n",
       "74               1.0             0.676673  \n",
       "71               1.0             0.676673  \n",
       "76               1.0             0.676673  \n",
       "81               1.0             0.676673  \n",
       "82               1.0             0.676673  \n",
       "85               1.0             0.676673  \n",
       "72               1.0             0.676673  \n",
       "75               1.0             0.676673  \n",
       "83               1.0             0.676673  \n",
       "67               1.0             0.676673  \n",
       "78               1.0             0.676673  \n",
       "84               1.0             0.676673  \n",
       "65               1.0             0.676673  \n",
       "93               1.0             0.676673  \n",
       "88               1.0             0.676673  \n",
       "66               1.0             0.676673  \n",
       "87               1.0             0.676673  \n",
       "58               1.0             0.676673  \n",
       "61               1.0             0.676673  \n",
       "64               1.0             0.676673  \n",
       "92               1.0             0.676673  \n",
       "90               1.0             0.676673  \n",
       "86               1.0             0.676673  \n",
       "..               ...                  ...  \n",
       "30               1.0             0.676673  \n",
       "28               1.0             0.676673  \n",
       "27               1.0             0.676673  \n",
       "25               1.0             0.676673  \n",
       "24               1.0             0.676673  \n",
       "26               1.0             0.676673  \n",
       "22               1.0             0.676673  \n",
       "21               1.0             0.676673  \n",
       "23               1.0             0.676673  \n",
       "20               1.0             0.676673  \n",
       "19               1.0             0.676673  \n",
       "18               1.0             0.676673  \n",
       "17               1.0             0.676673  \n",
       "16               1.0             0.676673  \n",
       "14               1.0             0.676673  \n",
       "15               1.0             0.676673  \n",
       "12               1.0             0.676673  \n",
       "13               1.0             0.676673  \n",
       "11               1.0             0.676673  \n",
       "10               1.0             0.676673  \n",
       "9                1.0             0.676673  \n",
       "6                1.0             0.676673  \n",
       "8                1.0             0.676673  \n",
       "7                1.0             0.676673  \n",
       "5                1.0             0.676673  \n",
       "1                1.0             0.676673  \n",
       "4                1.0             0.676673  \n",
       "3                1.0             0.676673  \n",
       "2                1.0             0.676673  \n",
       "0                1.0             0.676673  \n",
       "\n",
       "[98 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_stats_red = pca_stats[\n",
    "    ['param_feat__n_components', \n",
    "     'mean_test_roc_auc', \n",
    "     'mean_test_accuracy', \n",
    "     'mean_test_recall', \n",
    "     'mean_test_precision']\n",
    "]\n",
    "\n",
    "pca_stats_red.sort_values(\n",
    "             ['mean_test_roc_auc', \n",
    "              'mean_test_accuracy', \n",
    "              'mean_test_recall', \n",
    "              'mean_test_precision']\n",
    "             , ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 392 candidates, totalling 3920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed: 59.5min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4658ac7fdc79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                        )\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mgridsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('feat', KernelPCA(n_components=None)),\n",
    "    ('classify', SVC())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'feat__n_components': range(2, 100),\n",
    "    'feat__kernel': ['poly', 'rbf', 'sigmoid', 'cosine']\n",
    "}\n",
    "\n",
    "gridsrc = GridSearchCV(clf, \n",
    "                        cv=10, \n",
    "                        param_grid=params,\n",
    "                        scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'],\n",
    "                        verbose=2,\n",
    "                        n_jobs=5,\n",
    "                        refit=False\n",
    "                       )\n",
    "gridsrc.fit(X,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_stats = pd.concat(dfs, ignore_index=True)\n",
    "kpca_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_stats.groupby(['kernel','components']).mean().sort_values(['test_accuracy', 'test_recall', 'test_precision'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
