{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Able to specify which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "orig_SR = 44100\n",
    "orig_blocksize = int(orig_SR * 5)\n",
    "orig_overlap = 0 #int(orig_SR/4)\n",
    "\n",
    "SR = 16000\n",
    "blocksize = int(SR * 5)\n",
    "overlap = 0 #int(SR/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Here we load the csv that describes each file in the dataset. We add a high level category that is defined in the ESC-50 documentation. This we realize is anthetical to true training, it is a stopgap for when we use NLP to classify tags into these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_db='../../ESC-50/'\n",
    "audio_dir = path_to_db + 'audio/'\n",
    "dataset = pd.read_csv(path_to_db + 'meta/esc50.csv')\n",
    "classes = [None] * 50\n",
    "h_classes = ['Human & Animal', 'Interacting Materials']\n",
    "mapping = {'dog': 0,'rooster': 0,'pig': 0,'cow': 0,'frog': 0,'cat': 0,'hen': 0,\n",
    "            'insects': 0,'sheep': 0,'crow': 0,'rain': 1,'sea_waves': 1,'crackling_fire': 1,\n",
    "            'crickets': 0,'chirping_birds': 0,'water_drops': 1,'wind': 1,'pouring_water': 1,\n",
    "            'toilet_flush': 1,'thunderstorm': 1,'crying_baby': 0,'sneezing': 0,'clapping': 0,\n",
    "            'breathing': 0,'coughing': 0,'footsteps': 1,'laughing': 0,'brushing_teeth': 1,\n",
    "            'snoring': 0,'drinking_sipping': 1,'door_wood_knock': 1,'mouse_click': 1,\n",
    "            'keyboard_typing': 1,'door_wood_creaks': 1,'can_opening': 1,'washing_machine': 1,\n",
    "            'vacuum_cleaner': 1,'clock_alarm': 1,'clock_tick': 1,'glass_breaking':1,'helicopter': 1,\n",
    "            'chainsaw': 1,'siren': 1,'car_horn': 1,'engine': 1,'train': 1,'church_bells': 1,\n",
    "            'airplane': 1,'fireworks': 1,'hand_saw': 1,\n",
    "            }\n",
    "dataset['h_target'] = None\n",
    "for index, row in dataset.iterrows():\n",
    "    target = row['target']\n",
    "    classes[target] = row['category']\n",
    "    dataset.loc[index, 'h_target'] = mapping[row['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "      <th>h_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take  \\\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A   \n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A   \n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A   \n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B   \n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A   \n",
       "\n",
       "   h_target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(9, 9), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (dropout): Dropout2d(p=0.2, inplace=False)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=2, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 9)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 5)\n",
    "        self.norm = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(7, 7)\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.dropout = nn.Dropout2d(p=0.2)\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(64,32)\n",
    "        self.fc4 = nn.Linear(32,2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n"
     ]
    }
   ],
   "source": [
    "# load data:\n",
    "from PIL import Image\n",
    "import os \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class trainset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        root = \"./data2/\"\n",
    "        self.data_list = []\n",
    "        self.label_list = []\n",
    "        for root, dir, files in os.walk(\"./data2/\"):\n",
    "            for file in files:\n",
    "                if file.find('.npy')!= -1:\n",
    "                    self.data_list.append(os.path.join(root, file))\n",
    "                    self.label_list.append(int(root[13:]))\n",
    "        print(len(self.data_list), len(self.label_list))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        path = self.data_list[index]\n",
    "#         data = []\n",
    "#         label = []\n",
    "        fname = path.split(\"/\")[-1][:-4]+\".wav\"\n",
    "#         print(fname)\n",
    "        data = np.load(path,allow_pickle = True)\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "#         data = np.asarray(Image.open(path))\n",
    "        label = float(dataset[dataset[\"filename\"]==fname][\"h_target\"].values[0])\n",
    "#         print(label)\n",
    "    \n",
    "#         print(data.shape)\n",
    "#         data = np.asarray(data)\n",
    "        label = np.asarray(label)\n",
    "        \n",
    "        return data, label\n",
    "dataloader = trainset()\n",
    "data,label = dataloader.__getitem__(5)\n",
    "# print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.660237550735474\n",
      "Epoch: 0  val_loss: 0.6985870897769928\n",
      "Epoch: 0  val_accuracy: 0.462890625\n",
      "===========Phase: Train============\n",
      "Training Time: 171.8205370903015\n",
      "Epoch: 0  train_loss: 0.6489567664953378\n",
      "Epoch: 0  train_accuracy: 0.6359675480769231\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.037136793136597\n",
      "Epoch: 1  val_loss: 0.6450876593589783\n",
      "Epoch: 1  val_accuracy: 0.615234375\n",
      "===========Phase: Train============\n",
      "Training Time: 167.29679131507874\n",
      "Epoch: 1  train_loss: 0.6152861072466924\n",
      "Epoch: 1  train_accuracy: 0.6891526442307693\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.475305795669556\n",
      "Epoch: 2  val_loss: 0.6146249771118164\n",
      "Epoch: 2  val_accuracy: 0.66796875\n",
      "===========Phase: Train============\n",
      "Training Time: 168.85869979858398\n",
      "Epoch: 2  train_loss: 0.5798344749670762\n",
      "Epoch: 2  train_accuracy: 0.7286658653846154\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.698755979537964\n",
      "Epoch: 3  val_loss: 0.5713344812393188\n",
      "Epoch: 3  val_accuracy: 0.6875\n",
      "===========Phase: Train============\n",
      "Training Time: 167.17762351036072\n",
      "Epoch: 3  train_loss: 0.5480339985627395\n",
      "Epoch: 3  train_accuracy: 0.7644230769230769\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.223135948181152\n",
      "Epoch: 4  val_loss: 0.5681455358862877\n",
      "Epoch: 4  val_accuracy: 0.72265625\n",
      "===========Phase: Train============\n",
      "Training Time: 168.24494862556458\n",
      "Epoch: 4  train_loss: 0.5527538657188416\n",
      "Epoch: 4  train_accuracy: 0.7677283653846154\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.242868900299072\n",
      "Epoch: 5  val_loss: 0.5532256439328194\n",
      "Epoch: 5  val_accuracy: 0.708984375\n",
      "===========Phase: Train============\n",
      "Training Time: 168.32273244857788\n",
      "Epoch: 5  train_loss: 0.5050390179340656\n",
      "Epoch: 5  train_accuracy: 0.8087439903846154\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.111772537231445\n",
      "Epoch: 6  val_loss: 0.6469027251005173\n",
      "Epoch: 6  val_accuracy: 0.708984375\n",
      "===========Phase: Train============\n",
      "Training Time: 170.72945523262024\n",
      "Epoch: 6  train_loss: 0.5028078326812158\n",
      "Epoch: 6  train_accuracy: 0.818359375\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.038711309432983\n",
      "Epoch: 7  val_loss: 0.5332783460617065\n",
      "Epoch: 7  val_accuracy: 0.75390625\n",
      "===========Phase: Train============\n",
      "Training Time: 167.7414493560791\n",
      "Epoch: 7  train_loss: 0.4714610301531278\n",
      "Epoch: 7  train_accuracy: 0.8482572115384616\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.118239641189575\n",
      "Epoch: 8  val_loss: 0.4740506708621979\n",
      "Epoch: 8  val_accuracy: 0.80078125\n",
      "===========Phase: Train============\n",
      "Training Time: 166.89865589141846\n",
      "Epoch: 8  train_loss: 0.4540017522298373\n",
      "Epoch: 8  train_accuracy: 0.8566706730769231\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 13.970301389694214\n",
      "Epoch: 9  val_loss: 0.5588616505265236\n",
      "Epoch: 9  val_accuracy: 0.744140625\n",
      "===========Phase: Train============\n",
      "Training Time: 167.38784885406494\n",
      "Epoch: 9  train_loss: 0.4407215714454651\n",
      "Epoch: 9  train_accuracy: 0.8589242788461539\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.132330417633057\n",
      "Epoch: 10  val_loss: 0.4504384621977806\n",
      "Epoch: 10  val_accuracy: 0.810546875\n",
      "===========Phase: Train============\n",
      "Training Time: 167.04929566383362\n",
      "Epoch: 10  train_loss: 0.4161777702661661\n",
      "Epoch: 10  train_accuracy: 0.8772536057692307\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.037035703659058\n",
      "Epoch: 11  val_loss: 0.48727258294820786\n",
      "Epoch: 11  val_accuracy: 0.77734375\n",
      "===========Phase: Train============\n",
      "Training Time: 167.2098925113678\n",
      "Epoch: 11  train_loss: 0.3983690394805028\n",
      "Epoch: 11  train_accuracy: 0.8855168269230769\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.108109712600708\n",
      "Epoch: 12  val_loss: 0.5655176192522049\n",
      "Epoch: 12  val_accuracy: 0.783203125\n",
      "===========Phase: Train============\n",
      "Training Time: 167.26461029052734\n",
      "Epoch: 12  train_loss: 0.4266578027835259\n",
      "Epoch: 12  train_accuracy: 0.8607271634615384\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.163218975067139\n",
      "Epoch: 13  val_loss: 0.5711264088749886\n",
      "Epoch: 13  val_accuracy: 0.771484375\n",
      "===========Phase: Train============\n",
      "Training Time: 167.4208860397339\n",
      "Epoch: 13  train_loss: 0.40949575717632586\n",
      "Epoch: 13  train_accuracy: 0.8802584134615384\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.112212419509888\n",
      "Epoch: 14  val_loss: 0.5425489470362663\n",
      "Epoch: 14  val_accuracy: 0.76953125\n",
      "===========Phase: Train============\n",
      "Training Time: 167.6894223690033\n",
      "Epoch: 14  train_loss: 0.4052422046661377\n",
      "Epoch: 14  train_accuracy: 0.8837139423076923\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 13.963117122650146\n",
      "Epoch: 15  val_loss: 0.4622495174407959\n",
      "Epoch: 15  val_accuracy: 0.783203125\n",
      "===========Phase: Train============\n",
      "Training Time: 167.7832112312317\n",
      "Epoch: 15  train_loss: 0.36348416255070615\n",
      "Epoch: 15  train_accuracy: 0.9057992788461539\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.035122871398926\n",
      "Epoch: 16  val_loss: 0.5043854713439941\n",
      "Epoch: 16  val_accuracy: 0.755859375\n",
      "===========Phase: Train============\n",
      "Training Time: 168.0385127067566\n",
      "Epoch: 16  train_loss: 0.38737993286206174\n",
      "Epoch: 16  train_accuracy: 0.8970853365384616\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.082612991333008\n",
      "Epoch: 17  val_loss: 0.46933647990226746\n",
      "Epoch: 17  val_accuracy: 0.771484375\n",
      "===========Phase: Train============\n",
      "Training Time: 168.6186671257019\n",
      "Epoch: 17  train_loss: 0.3574476081591386\n",
      "Epoch: 17  train_accuracy: 0.904296875\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.093654155731201\n",
      "Epoch: 18  val_loss: 0.42263583838939667\n",
      "Epoch: 18  val_accuracy: 0.8203125\n",
      "===========Phase: Train============\n",
      "Training Time: 168.26959037780762\n",
      "Epoch: 18  train_loss: 0.3354385243012355\n",
      "Epoch: 18  train_accuracy: 0.9224759615384616\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.07609224319458\n",
      "Epoch: 19  val_loss: 0.40067512542009354\n",
      "Epoch: 19  val_accuracy: 0.845703125\n",
      "===========Phase: Train============\n",
      "Training Time: 168.6797115802765\n",
      "Epoch: 19  train_loss: 0.325545446230815\n",
      "Epoch: 19  train_accuracy: 0.9352463942307693\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.114901304244995\n",
      "Epoch: 20  val_loss: 0.4066993221640587\n",
      "Epoch: 20  val_accuracy: 0.822265625\n",
      "===========Phase: Train============\n",
      "Training Time: 168.43427276611328\n",
      "Epoch: 20  train_loss: 0.3117711463799843\n",
      "Epoch: 20  train_accuracy: 0.9376502403846154\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.117865324020386\n",
      "Epoch: 21  val_loss: 0.40597980469465256\n",
      "Epoch: 21  val_accuracy: 0.8671875\n",
      "===========Phase: Train============\n",
      "Training Time: 168.57501077651978\n",
      "Epoch: 21  train_loss: 0.3154670045926021\n",
      "Epoch: 21  train_accuracy: 0.9387019230769231\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.020019054412842\n",
      "Epoch: 22  val_loss: 0.3555806428194046\n",
      "Epoch: 22  val_accuracy: 0.888671875\n",
      "===========Phase: Train============\n",
      "Training Time: 168.50012278556824\n",
      "Epoch: 22  train_loss: 0.2903004724245805\n",
      "Epoch: 22  train_accuracy: 0.9505709134615384\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.057076692581177\n",
      "Epoch: 23  val_loss: 0.42966578155755997\n",
      "Epoch: 23  val_accuracy: 0.826171875\n",
      "===========Phase: Train============\n",
      "Training Time: 168.9112606048584\n",
      "Epoch: 23  train_loss: 0.2769483717588278\n",
      "Epoch: 23  train_accuracy: 0.9517728365384616\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.03819990158081\n",
      "Epoch: 24  val_loss: 0.3601878136396408\n",
      "Epoch: 24  val_accuracy: 0.84375\n",
      "===========Phase: Train============\n",
      "Training Time: 168.44553017616272\n",
      "Epoch: 24  train_loss: 0.3126877867258512\n",
      "Epoch: 24  train_accuracy: 0.9332932692307693\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.280527114868164\n",
      "Epoch: 25  val_loss: 0.518528550863266\n",
      "Epoch: 25  val_accuracy: 0.7421875\n",
      "===========Phase: Train============\n",
      "Training Time: 168.28259754180908\n",
      "Epoch: 25  train_loss: 0.2884698384083234\n",
      "Epoch: 25  train_accuracy: 0.9441105769230769\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.141561031341553\n",
      "Epoch: 26  val_loss: 0.3256876766681671\n",
      "Epoch: 26  val_accuracy: 0.888671875\n",
      "===========Phase: Train============\n",
      "Training Time: 168.49759912490845\n",
      "Epoch: 26  train_loss: 0.27677299884649426\n",
      "Epoch: 26  train_accuracy: 0.9529747596153846\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Phase: Val============\n",
      "Validation Time: 14.040440320968628\n",
      "Epoch: 27  val_loss: 0.3476894944906235\n",
      "Epoch: 27  val_accuracy: 0.83984375\n",
      "===========Phase: Train============\n",
      "Training Time: 168.33998727798462\n",
      "Epoch: 27  train_loss: 0.25799522262353164\n",
      "Epoch: 27  train_accuracy: 0.9660456730769231\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.196431159973145\n",
      "Epoch: 28  val_loss: 0.39139188826084137\n",
      "Epoch: 28  val_accuracy: 0.853515625\n",
      "===========Phase: Train============\n",
      "Training Time: 168.49377155303955\n",
      "Epoch: 28  train_loss: 0.2850327342748642\n",
      "Epoch: 28  train_accuracy: 0.9532752403846154\n",
      "\n",
      "===========Phase: Val============\n",
      "Validation Time: 14.146916151046753\n",
      "Epoch: 29  val_loss: 0.39415503293275833\n",
      "Epoch: 29  val_accuracy: 0.8125\n",
      "===========Phase: Train============\n",
      "Training Time: 168.4154772758484\n",
      "Epoch: 29  train_loss: 0.24700509126369768\n",
      "Epoch: 29  train_accuracy: 0.9645432692307693\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "\n",
    "# model = BaseNet()\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "validation_split = .2\n",
    "random_seed= 42\n",
    "shuffle_dataset = True\n",
    "dataset_size = 2000\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "datasets  = trainset()\n",
    "trainloader = torch.utils.data.DataLoader(datasets, batch_size=128, \n",
    "                                           sampler=train_sampler)\n",
    "valloader = torch.utils.data.DataLoader(datasets, batch_size=128,\n",
    "                                                sampler=valid_sampler)\n",
    "\n",
    "val_history = []\n",
    "val_loss_hist = []\n",
    "train_history = []\n",
    "train_loss_hist = []\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    \n",
    "########## Validation ###########\n",
    "    \n",
    "    count = 0\n",
    "    running_accuracy = 0\n",
    "    running_loss = 0\n",
    "    t1 = time.time()\n",
    "    for i, data in enumerate(valloader, 0):\n",
    "        count += 1\n",
    "        inputs, labels = data\n",
    "        labels = labels.long()\n",
    "        inputs = inputs.float()\n",
    "        outputs = model(inputs)\n",
    "        val_loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        acc_val = torch.eq(preds, labels).float().mean()\n",
    "        running_accuracy += acc_val.item()\n",
    "        running_loss += val_loss.item()\n",
    "        \n",
    "    running_accuracy /= count\n",
    "    running_loss /= count\n",
    "    val_history.append(running_accuracy)\n",
    "    val_loss_hist.append(running_loss)\n",
    "    t2 = time.time()\n",
    "    print(\"===========Phase: Val============\")\n",
    "    print(\"Validation Time: {}\".format(t2 - t1))\n",
    "    print(\"Epoch: {}  val_loss: {}\".format(epoch, running_loss))\n",
    "    print(\"Epoch: {}  val_accuracy: {}\".format(epoch, running_accuracy))\n",
    "    \n",
    "######### Training ###########   \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "    training_accuracy = 0\n",
    "    t1 = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        count += 1\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        acc_train = torch.eq(preds, labels).float().mean()\n",
    "        running_accuracy += acc_train.item()\n",
    "        \n",
    "    running_accuracy /= count\n",
    "    running_loss /= count\n",
    "    train_history.append(running_accuracy)\n",
    "    train_loss_hist.append(running_loss)\n",
    "    t2 = time.time()\n",
    "    print(\"===========Phase: Train============\") \n",
    "    print(\"Training Time: {}\".format(t2 - t1))\n",
    "    print(\"Epoch: {}  train_loss: {}\".format(epoch, running_loss))\n",
    "    print(\"Epoch: {}  train_accuracy: {}\".format(epoch, running_accuracy))\n",
    "    print()\n",
    "        \n",
    "# # #             torch.save(net, 'toy_model.pt')\n",
    "        \n",
    "    \n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'hierarchical_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Level Shallow Nets\n",
    "Train binary shallow nets for high level categories(animals, natural, human, domestic, urban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "melspectrogram_1 (Melspectro (None, 128, 313, 1)       296064    \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 120, 305, 32)      2624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 17, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2176)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                69664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 371,553\n",
      "Trainable params: 75,489\n",
      "Non-trainable params: 296,064\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 80 samples\n",
      "Epoch 1/50\n",
      "1520/1520 [==============================] - 45s 30ms/step - loss: 0.6865 - acc: 0.6257 - val_loss: 0.6852 - val_acc: 0.6250\n",
      "Epoch 2/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.6588 - acc: 0.6914 - val_loss: 0.6382 - val_acc: 0.7125\n",
      "Epoch 3/50\n",
      "1520/1520 [==============================] - 60s 39ms/step - loss: 0.6417 - acc: 0.6842 - val_loss: 0.7140 - val_acc: 0.6500\n",
      "Epoch 4/50\n",
      "1520/1520 [==============================] - 63s 42ms/step - loss: 0.6180 - acc: 0.7211 - val_loss: 0.6904 - val_acc: 0.6375\n",
      "Epoch 5/50\n",
      "1520/1520 [==============================] - 56s 37ms/step - loss: 0.5878 - acc: 0.7368 - val_loss: 0.5997 - val_acc: 0.7375\n",
      "Epoch 6/50\n",
      "1520/1520 [==============================] - 46s 30ms/step - loss: 0.5580 - acc: 0.7447 - val_loss: 0.5929 - val_acc: 0.7375\n",
      "Epoch 7/50\n",
      "1520/1520 [==============================] - 46s 30ms/step - loss: 0.5388 - acc: 0.7480 - val_loss: 0.6217 - val_acc: 0.7500\n",
      "Epoch 8/50\n",
      "1520/1520 [==============================] - 48s 31ms/step - loss: 0.5386 - acc: 0.7500 - val_loss: 0.6063 - val_acc: 0.7750\n",
      "Epoch 9/50\n",
      "1520/1520 [==============================] - 47s 31ms/step - loss: 0.5243 - acc: 0.7559 - val_loss: 0.5969 - val_acc: 0.7750\n",
      "Epoch 10/50\n",
      "1520/1520 [==============================] - 46s 30ms/step - loss: 0.5020 - acc: 0.7711 - val_loss: 0.5442 - val_acc: 0.8000\n",
      "Epoch 11/50\n",
      "1520/1520 [==============================] - 47s 31ms/step - loss: 0.4872 - acc: 0.7789 - val_loss: 0.5043 - val_acc: 0.8125\n",
      "Epoch 12/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.4716 - acc: 0.7914 - val_loss: 0.5161 - val_acc: 0.8125\n",
      "Epoch 13/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.4590 - acc: 0.8013 - val_loss: 0.4932 - val_acc: 0.8125\n",
      "Epoch 14/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.4461 - acc: 0.8033 - val_loss: 0.5408 - val_acc: 0.8000\n",
      "Epoch 15/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.4513 - acc: 0.8053 - val_loss: 0.5500 - val_acc: 0.8000\n",
      "Epoch 16/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.4356 - acc: 0.8066 - val_loss: 0.4947 - val_acc: 0.7875\n",
      "Epoch 17/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.4276 - acc: 0.8105 - val_loss: 0.4822 - val_acc: 0.8125\n",
      "Epoch 18/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.4008 - acc: 0.8224 - val_loss: 0.5306 - val_acc: 0.7750\n",
      "Epoch 19/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.3798 - acc: 0.8342 - val_loss: 0.4987 - val_acc: 0.7875\n",
      "Epoch 20/50\n",
      "1520/1520 [==============================] - 45s 30ms/step - loss: 0.3583 - acc: 0.8454 - val_loss: 0.5236 - val_acc: 0.8000\n",
      "Epoch 21/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.3745 - acc: 0.8375 - val_loss: 0.5370 - val_acc: 0.7750\n",
      "Epoch 22/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.3509 - acc: 0.8467 - val_loss: 0.5508 - val_acc: 0.8000\n",
      "Epoch 23/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.3447 - acc: 0.8539 - val_loss: 0.5495 - val_acc: 0.8125\n",
      "Epoch 24/50\n",
      "1520/1520 [==============================] - 43s 29ms/step - loss: 0.3386 - acc: 0.8474 - val_loss: 0.7024 - val_acc: 0.7375\n",
      "Epoch 25/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.3186 - acc: 0.8625 - val_loss: 0.6126 - val_acc: 0.8000\n",
      "Epoch 26/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.3061 - acc: 0.8671 - val_loss: 0.5629 - val_acc: 0.8500\n",
      "Epoch 27/50\n",
      "1520/1520 [==============================] - 42s 28ms/step - loss: 0.2936 - acc: 0.8796 - val_loss: 0.6407 - val_acc: 0.8000\n",
      "Epoch 28/50\n",
      "1520/1520 [==============================] - 42s 28ms/step - loss: 0.2565 - acc: 0.8921 - val_loss: 0.7274 - val_acc: 0.8000\n",
      "Epoch 29/50\n",
      "1520/1520 [==============================] - 42s 28ms/step - loss: 0.2662 - acc: 0.8875 - val_loss: 0.6238 - val_acc: 0.8375\n",
      "Epoch 30/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.3039 - acc: 0.8770 - val_loss: 0.7718 - val_acc: 0.7500\n",
      "Epoch 31/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.2574 - acc: 0.8908 - val_loss: 0.7465 - val_acc: 0.8500\n",
      "Epoch 32/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.2470 - acc: 0.8974 - val_loss: 0.8428 - val_acc: 0.7750\n",
      "Epoch 33/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.2315 - acc: 0.9125 - val_loss: 0.6669 - val_acc: 0.8500\n",
      "Epoch 34/50\n",
      "1520/1520 [==============================] - 42s 28ms/step - loss: 0.2129 - acc: 0.9158 - val_loss: 0.6859 - val_acc: 0.8125\n",
      "Epoch 35/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.2041 - acc: 0.9204 - val_loss: 0.8206 - val_acc: 0.7875\n",
      "Epoch 36/50\n",
      "1520/1520 [==============================] - 42s 27ms/step - loss: 0.2195 - acc: 0.9171 - val_loss: 1.0659 - val_acc: 0.7500\n",
      "Epoch 37/50\n",
      "1520/1520 [==============================] - 42s 28ms/step - loss: 0.2139 - acc: 0.9079 - val_loss: 0.6901 - val_acc: 0.8125\n",
      "Epoch 38/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.2445 - acc: 0.8987 - val_loss: 0.7557 - val_acc: 0.7750\n",
      "Epoch 39/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.2097 - acc: 0.9178 - val_loss: 0.6545 - val_acc: 0.8375\n",
      "Epoch 40/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.1747 - acc: 0.9342 - val_loss: 0.6514 - val_acc: 0.8375\n",
      "Epoch 41/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.1597 - acc: 0.9375 - val_loss: 1.0204 - val_acc: 0.7875\n",
      "Epoch 42/50\n",
      "1520/1520 [==============================] - 42s 28ms/step - loss: 0.1645 - acc: 0.9454 - val_loss: 0.7242 - val_acc: 0.8375\n",
      "Epoch 43/50\n",
      "1520/1520 [==============================] - 42s 28ms/step - loss: 0.1442 - acc: 0.9480 - val_loss: 0.7833 - val_acc: 0.8125\n",
      "Epoch 44/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.1294 - acc: 0.9579 - val_loss: 1.1706 - val_acc: 0.7375\n",
      "Epoch 45/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.1177 - acc: 0.9599 - val_loss: 1.3136 - val_acc: 0.7750\n",
      "Epoch 46/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.1134 - acc: 0.9605 - val_loss: 1.1615 - val_acc: 0.7875\n",
      "Epoch 47/50\n",
      "1520/1520 [==============================] - 44s 29ms/step - loss: 0.1276 - acc: 0.9559 - val_loss: 0.9193 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "1520/1520 [==============================] - 42s 28ms/step - loss: 0.1197 - acc: 0.9632 - val_loss: 1.0381 - val_acc: 0.8125\n",
      "Epoch 49/50\n",
      "1520/1520 [==============================] - 42s 27ms/step - loss: 0.1362 - acc: 0.9474 - val_loss: 1.7027 - val_acc: 0.7125\n",
      "Epoch 50/50\n",
      "1520/1520 [==============================] - 43s 28ms/step - loss: 0.1569 - acc: 0.9428 - val_loss: 0.9151 - val_acc: 0.8000\n",
      "Train on 577 samples, validate on 31 samples\n",
      "Epoch 1/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 2.9396 - acc: 0.0433 - val_loss: 2.9380 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.9071 - acc: 0.0676 - val_loss: 2.9106 - val_acc: 0.0323\n",
      "Epoch 3/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.8612 - acc: 0.0797 - val_loss: 2.8814 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 2.8267 - acc: 0.0797 - val_loss: 2.8784 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 2.7903 - acc: 0.1075 - val_loss: 2.8491 - val_acc: 0.0323\n",
      "Epoch 6/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 2.7626 - acc: 0.1334 - val_loss: 2.8147 - val_acc: 0.0323\n",
      "Epoch 7/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 2.7444 - acc: 0.1352 - val_loss: 2.8251 - val_acc: 0.0323\n",
      "Epoch 8/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 2.7122 - acc: 0.1438 - val_loss: 2.7995 - val_acc: 0.0645\n",
      "Epoch 9/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.6525 - acc: 0.1716 - val_loss: 2.7495 - val_acc: 0.0968\n",
      "Epoch 10/50\n",
      "577/577 [==============================] - 16s 27ms/step - loss: 2.6237 - acc: 0.1837 - val_loss: 2.6883 - val_acc: 0.1290\n",
      "Epoch 11/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.5971 - acc: 0.1698 - val_loss: 2.7640 - val_acc: 0.1290\n",
      "Epoch 12/50\n",
      "577/577 [==============================] - 16s 27ms/step - loss: 2.5687 - acc: 0.1854 - val_loss: 2.6333 - val_acc: 0.1290\n",
      "Epoch 13/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.5156 - acc: 0.2340 - val_loss: 2.5651 - val_acc: 0.1613\n",
      "Epoch 14/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.4644 - acc: 0.2444 - val_loss: 2.5750 - val_acc: 0.1935\n",
      "Epoch 15/50\n",
      "577/577 [==============================] - 17s 30ms/step - loss: 2.3986 - acc: 0.2392 - val_loss: 2.6673 - val_acc: 0.2258\n",
      "Epoch 16/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 2.3368 - acc: 0.2773 - val_loss: 2.5805 - val_acc: 0.1935\n",
      "Epoch 17/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 2.3012 - acc: 0.2825 - val_loss: 2.4170 - val_acc: 0.2581\n",
      "Epoch 18/50\n",
      "577/577 [==============================] - 17s 30ms/step - loss: 2.2792 - acc: 0.3033 - val_loss: 2.4223 - val_acc: 0.1613\n",
      "Epoch 19/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.2149 - acc: 0.3206 - val_loss: 2.5469 - val_acc: 0.1613\n",
      "Epoch 20/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 2.1835 - acc: 0.3102 - val_loss: 2.5247 - val_acc: 0.1935\n",
      "Epoch 21/50\n",
      "577/577 [==============================] - 17s 30ms/step - loss: 2.1357 - acc: 0.3345 - val_loss: 2.5542 - val_acc: 0.2581\n",
      "Epoch 22/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 2.0983 - acc: 0.3241 - val_loss: 2.6133 - val_acc: 0.2258\n",
      "Epoch 23/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.1105 - acc: 0.3328 - val_loss: 2.7073 - val_acc: 0.2258\n",
      "Epoch 24/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.0687 - acc: 0.3484 - val_loss: 2.4810 - val_acc: 0.2903\n",
      "Epoch 25/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.0246 - acc: 0.3310 - val_loss: 2.7652 - val_acc: 0.1613\n",
      "Epoch 26/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 2.0070 - acc: 0.3744 - val_loss: 2.5335 - val_acc: 0.1935\n",
      "Epoch 27/50\n",
      "577/577 [==============================] - 16s 27ms/step - loss: 1.9585 - acc: 0.3865 - val_loss: 2.5654 - val_acc: 0.1935\n",
      "Epoch 28/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.8879 - acc: 0.4021 - val_loss: 2.9249 - val_acc: 0.1935\n",
      "Epoch 29/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.9267 - acc: 0.3934 - val_loss: 2.7318 - val_acc: 0.1935\n",
      "Epoch 30/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.8245 - acc: 0.4315 - val_loss: 2.7615 - val_acc: 0.2258\n",
      "Epoch 31/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.8074 - acc: 0.4246 - val_loss: 2.5232 - val_acc: 0.1935\n",
      "Epoch 32/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 1.7563 - acc: 0.4385 - val_loss: 3.0102 - val_acc: 0.1935\n",
      "Epoch 33/50\n",
      "577/577 [==============================] - 16s 27ms/step - loss: 1.7154 - acc: 0.4558 - val_loss: 2.3905 - val_acc: 0.3548\n",
      "Epoch 34/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.7822 - acc: 0.4541 - val_loss: 2.6437 - val_acc: 0.2258\n",
      "Epoch 35/50\n",
      "577/577 [==============================] - 16s 29ms/step - loss: 1.6983 - acc: 0.4454 - val_loss: 2.6439 - val_acc: 0.2258\n",
      "Epoch 36/50\n",
      "577/577 [==============================] - 16s 27ms/step - loss: 1.6333 - acc: 0.4766 - val_loss: 2.5337 - val_acc: 0.2581\n",
      "Epoch 37/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 1.6606 - acc: 0.4835 - val_loss: 2.9041 - val_acc: 0.1935\n",
      "Epoch 38/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.6264 - acc: 0.4575 - val_loss: 2.6070 - val_acc: 0.2581\n",
      "Epoch 39/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 1.6250 - acc: 0.4575 - val_loss: 2.9371 - val_acc: 0.2258\n",
      "Epoch 40/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.5346 - acc: 0.5113 - val_loss: 2.9579 - val_acc: 0.1935\n",
      "Epoch 41/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.5442 - acc: 0.4887 - val_loss: 2.7701 - val_acc: 0.2581\n",
      "Epoch 42/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.5186 - acc: 0.4939 - val_loss: 2.5436 - val_acc: 0.2903\n",
      "Epoch 43/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.4802 - acc: 0.5095 - val_loss: 2.8608 - val_acc: 0.1935\n",
      "Epoch 44/50\n",
      "577/577 [==============================] - 16s 29ms/step - loss: 1.3786 - acc: 0.5355 - val_loss: 3.0876 - val_acc: 0.2581\n",
      "Epoch 45/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.4103 - acc: 0.5373 - val_loss: 3.0127 - val_acc: 0.1935\n",
      "Epoch 46/50\n",
      "577/577 [==============================] - 16s 28ms/step - loss: 1.3733 - acc: 0.5182 - val_loss: 3.0537 - val_acc: 0.2258\n",
      "Epoch 47/50\n",
      "577/577 [==============================] - 16s 27ms/step - loss: 1.3324 - acc: 0.5425 - val_loss: 2.9378 - val_acc: 0.2258\n",
      "Epoch 48/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 1.3187 - acc: 0.5442 - val_loss: 3.3488 - val_acc: 0.1935\n",
      "Epoch 49/50\n",
      "577/577 [==============================] - 17s 30ms/step - loss: 1.2906 - acc: 0.5511 - val_loss: 3.1889 - val_acc: 0.1935\n",
      "Epoch 50/50\n",
      "577/577 [==============================] - 17s 29ms/step - loss: 1.3177 - acc: 0.5667 - val_loss: 2.9699 - val_acc: 0.1935\n",
      "Train on 942 samples, validate on 50 samples\n",
      "Epoch 1/50\n",
      "942/942 [==============================] - 27s 29ms/step - loss: 3.4188 - acc: 0.0329 - val_loss: 3.4059 - val_acc: 0.0400\n",
      "Epoch 2/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 3.3821 - acc: 0.0403 - val_loss: 3.3679 - val_acc: 0.0200\n",
      "Epoch 3/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 3.3271 - acc: 0.0467 - val_loss: 3.3319 - val_acc: 0.0200\n",
      "Epoch 4/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 3.2670 - acc: 0.0658 - val_loss: 3.3026 - val_acc: 0.0200\n",
      "Epoch 5/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 3.2257 - acc: 0.0669 - val_loss: 3.2837 - val_acc: 0.0200\n",
      "Epoch 6/50\n",
      "942/942 [==============================] - 26s 27ms/step - loss: 3.2115 - acc: 0.0626 - val_loss: 3.2671 - val_acc: 0.0200\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942/942 [==============================] - 26s 27ms/step - loss: 3.1531 - acc: 0.0817 - val_loss: 3.2304 - val_acc: 0.0200\n",
      "Epoch 8/50\n",
      "942/942 [==============================] - 27s 29ms/step - loss: 3.1282 - acc: 0.0828 - val_loss: 3.2173 - val_acc: 0.0200\n",
      "Epoch 9/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 3.0945 - acc: 0.1136 - val_loss: 3.1836 - val_acc: 0.0200\n",
      "Epoch 10/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 3.0966 - acc: 0.1178 - val_loss: 3.1231 - val_acc: 0.0400\n",
      "Epoch 11/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 3.0418 - acc: 0.1316 - val_loss: 3.1072 - val_acc: 0.0200\n",
      "Epoch 12/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 3.0123 - acc: 0.1338 - val_loss: 3.1074 - val_acc: 0.0800\n",
      "Epoch 13/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 2.9774 - acc: 0.1497 - val_loss: 3.0710 - val_acc: 0.0800\n",
      "Epoch 14/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 2.9431 - acc: 0.1582 - val_loss: 3.0237 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "942/942 [==============================] - 26s 27ms/step - loss: 2.8789 - acc: 0.1677 - val_loss: 2.9559 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 2.8416 - acc: 0.1815 - val_loss: 2.9089 - val_acc: 0.1400\n",
      "Epoch 17/50\n",
      "942/942 [==============================] - 26s 27ms/step - loss: 2.7902 - acc: 0.1847 - val_loss: 2.8721 - val_acc: 0.1200\n",
      "Epoch 18/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 2.7521 - acc: 0.1943 - val_loss: 2.7629 - val_acc: 0.1600\n",
      "Epoch 19/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 2.6928 - acc: 0.2081 - val_loss: 2.7042 - val_acc: 0.2800\n",
      "Epoch 20/50\n",
      "942/942 [==============================] - 27s 29ms/step - loss: 2.6606 - acc: 0.2251 - val_loss: 2.6392 - val_acc: 0.2600\n",
      "Epoch 21/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 2.5788 - acc: 0.2091 - val_loss: 2.5581 - val_acc: 0.1200\n",
      "Epoch 22/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 2.5579 - acc: 0.2463 - val_loss: 2.5149 - val_acc: 0.2000\n",
      "Epoch 23/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 2.4896 - acc: 0.2442 - val_loss: 2.3905 - val_acc: 0.2200\n",
      "Epoch 24/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 2.4289 - acc: 0.2643 - val_loss: 2.3696 - val_acc: 0.1800\n",
      "Epoch 25/50\n",
      "942/942 [==============================] - 27s 29ms/step - loss: 2.3889 - acc: 0.2643 - val_loss: 2.3096 - val_acc: 0.1800\n",
      "Epoch 26/50\n",
      "942/942 [==============================] - 26s 27ms/step - loss: 2.3557 - acc: 0.2771 - val_loss: 2.2806 - val_acc: 0.2200\n",
      "Epoch 27/50\n",
      "942/942 [==============================] - 27s 29ms/step - loss: 2.3118 - acc: 0.2675 - val_loss: 2.2066 - val_acc: 0.2600\n",
      "Epoch 28/50\n",
      "942/942 [==============================] - 27s 29ms/step - loss: 2.3057 - acc: 0.2813 - val_loss: 2.1610 - val_acc: 0.2600\n",
      "Epoch 29/50\n",
      "942/942 [==============================] - 26s 27ms/step - loss: 2.2231 - acc: 0.2792 - val_loss: 2.2035 - val_acc: 0.2400\n",
      "Epoch 30/50\n",
      "942/942 [==============================] - 27s 29ms/step - loss: 2.1968 - acc: 0.3004 - val_loss: 2.1083 - val_acc: 0.3000\n",
      "Epoch 31/50\n",
      "942/942 [==============================] - 26s 27ms/step - loss: 2.1751 - acc: 0.3132 - val_loss: 2.0717 - val_acc: 0.3000\n",
      "Epoch 32/50\n",
      "942/942 [==============================] - 26s 27ms/step - loss: 2.1265 - acc: 0.3174 - val_loss: 2.1024 - val_acc: 0.3000\n",
      "Epoch 33/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 2.1074 - acc: 0.3068 - val_loss: 2.0257 - val_acc: 0.3400\n",
      "Epoch 34/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 2.1028 - acc: 0.3195 - val_loss: 2.0133 - val_acc: 0.3400\n",
      "Epoch 35/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 2.0968 - acc: 0.3132 - val_loss: 2.1098 - val_acc: 0.2600\n",
      "Epoch 36/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 2.0076 - acc: 0.3344 - val_loss: 2.2258 - val_acc: 0.2400\n",
      "Epoch 37/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 2.0777 - acc: 0.3036 - val_loss: 2.0355 - val_acc: 0.3000\n",
      "Epoch 38/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 1.9460 - acc: 0.3694 - val_loss: 2.0699 - val_acc: 0.2800\n",
      "Epoch 39/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 1.9700 - acc: 0.3599 - val_loss: 1.9626 - val_acc: 0.3000\n",
      "Epoch 40/50\n",
      "942/942 [==============================] - 27s 29ms/step - loss: 1.9770 - acc: 0.3577 - val_loss: 2.0563 - val_acc: 0.3000\n",
      "Epoch 41/50\n",
      "942/942 [==============================] - 27s 29ms/step - loss: 1.9286 - acc: 0.3620 - val_loss: 1.9766 - val_acc: 0.3600\n",
      "Epoch 42/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 1.9115 - acc: 0.3694 - val_loss: 2.0141 - val_acc: 0.2600\n",
      "Epoch 43/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 1.9134 - acc: 0.3705 - val_loss: 2.1055 - val_acc: 0.2600\n",
      "Epoch 44/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 1.8900 - acc: 0.3949 - val_loss: 1.9964 - val_acc: 0.3200\n",
      "Epoch 45/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 1.8915 - acc: 0.3832 - val_loss: 2.0189 - val_acc: 0.3200\n",
      "Epoch 46/50\n",
      "942/942 [==============================] - 27s 28ms/step - loss: 1.8503 - acc: 0.3747 - val_loss: 2.0644 - val_acc: 0.3000\n",
      "Epoch 47/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 1.8360 - acc: 0.3864 - val_loss: 2.1178 - val_acc: 0.3200\n",
      "Epoch 48/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 1.8154 - acc: 0.3896 - val_loss: 2.2722 - val_acc: 0.2600\n",
      "Epoch 49/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 1.8735 - acc: 0.3907 - val_loss: 2.1098 - val_acc: 0.2600\n",
      "Epoch 50/50\n",
      "942/942 [==============================] - 26s 28ms/step - loss: 1.8272 - acc: 0.3800 - val_loss: 2.0327 - val_acc: 0.2800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN_Multilayer(a_batch_size=128, a_epochs=50, batch_size=128, epochs=50,\n",
       "        i_batch_size=128, i_epochs=50, validation_split=0.05, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cnnmult import CNN_Multilayer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "clf = CNN_Multilayer()\n",
    "\n",
    "clf.fit(train_X, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
