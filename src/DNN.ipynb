{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from preprocess import Audio_Processor\n",
    "import data_utils as du\n",
    "from sklearn import metrics\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_db='../ESC-50/'\n",
    "ps = Audio_Processor(path_to_db + 'audio/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Here we load the csv that describes each file in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(path_to_db + 'meta/esc50.csv')\n",
    "classes = [None] * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dataset.iterrows():\n",
    "    target = row['target']\n",
    "    classes[target] = row['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data = pd.concat([ps.process_fold(fld) for fld in range(1,6)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = c_data.target.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data, scalar = du.normalize_data(c_data, 'target')\n",
    "train, test = du.split_training_test(c_data, 0.2)\n",
    "train_X = train.drop(columns=['target'])\n",
    "train_y = train.target\n",
    "test_X = test.drop(columns=['target'])\n",
    "test_y = test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall DNN\n",
    "Train overall net for classifying all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 38)                1482      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 38)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 38)                1482      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 38)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                1950      \n",
      "=================================================================\n",
      "Total params: 4,914\n",
      "Trainable params: 4,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clas = dnn_clas.create_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "310994/310994 [==============================] - 25s 80us/step - loss: 3.1447 - acc: 0.1711\n",
      "Epoch 2/20\n",
      "310994/310994 [==============================] - 16s 51us/step - loss: 2.7351 - acc: 0.2584\n",
      "Epoch 3/20\n",
      "310994/310994 [==============================] - 16s 51us/step - loss: 2.6327 - acc: 0.2811\n",
      "Epoch 4/20\n",
      "310994/310994 [==============================] - 15s 49us/step - loss: 2.5870 - acc: 0.2909\n",
      "Epoch 5/20\n",
      "310994/310994 [==============================] - 15s 48us/step - loss: 2.5535 - acc: 0.2992\n",
      "Epoch 6/20\n",
      "310994/310994 [==============================] - 15s 48us/step - loss: 2.5377 - acc: 0.3024\n",
      "Epoch 7/20\n",
      "310994/310994 [==============================] - 15s 47us/step - loss: 2.5181 - acc: 0.3075\n",
      "Epoch 8/20\n",
      "310994/310994 [==============================] - 15s 48us/step - loss: 2.5094 - acc: 0.3102\n",
      "Epoch 9/20\n",
      "310994/310994 [==============================] - 15s 48us/step - loss: 2.5011 - acc: 0.3131\n",
      "Epoch 10/20\n",
      "310994/310994 [==============================] - 15s 49us/step - loss: 2.4937 - acc: 0.3145\n",
      "Epoch 11/20\n",
      "310994/310994 [==============================] - 15s 48us/step - loss: 2.4899 - acc: 0.3167\n",
      "Epoch 12/20\n",
      "310994/310994 [==============================] - 15s 48us/step - loss: 2.4845 - acc: 0.3175\n",
      "Epoch 13/20\n",
      "310994/310994 [==============================] - 15s 47us/step - loss: 2.4783 - acc: 0.3187\n",
      "Epoch 14/20\n",
      "310994/310994 [==============================] - 15s 48us/step - loss: 2.4746 - acc: 0.3196\n",
      "Epoch 15/20\n",
      "310994/310994 [==============================] - 15s 47us/step - loss: 2.4708 - acc: 0.3203\n",
      "Epoch 16/20\n",
      "310994/310994 [==============================] - 15s 48us/step - loss: 2.4690 - acc: 0.3215\n",
      "Epoch 17/20\n",
      "310994/310994 [==============================] - 15s 47us/step - loss: 2.4684 - acc: 0.3216\n",
      "Epoch 18/20\n",
      "310994/310994 [==============================] - 15s 47us/step - loss: 2.4677 - acc: 0.3233\n",
      "Epoch 19/20\n",
      "310994/310994 [==============================] - 15s 47us/step - loss: 2.4641 - acc: 0.3226\n",
      "Epoch 20/20\n",
      "310994/310994 [==============================] - 15s 47us/step - loss: 2.4627 - acc: 0.3250\n"
     ]
    }
   ],
   "source": [
    "dnn_clas.fit(clas, train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77749/77749 [==============================] - 119s 2ms/step\n",
      "Test loss: 2.08641931449647\n",
      "Test accuracy: 0.4369316647159449\n"
     ]
    }
   ],
   "source": [
    "dnn_clas.score(clas, test_X, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "Here we get the log likelihood of the categories when matched with its training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = process_fold(5)\n",
    "test, _ = du.normalize_data(test, 'target', scalar)\n",
    "test_X = test.drop(columns=['target'])\n",
    "test_y = test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(test_y, list(clas.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_plots import plot_confusion_matrix\n",
    "cm = metrics.confusion_matrix(test_y, list(clas.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(25,25))\n",
    "plot_confusion_matrix(cm, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Probability of File Category\n",
    "We run our classifier over the file's audio frames and use basic averages to determine the probability of it belonging to a class. (Should in future have classifier give probability scores for each category for each frame but... thats future work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def file_probability(filename, clas, preprocessor, class_list):\n",
    "    test_file = pd.DataFrame(preprocessor.preprocess(filename))\n",
    "    predictions = [class_list[i] for i in list(clas.predict(test_file))]\n",
    "    sns.countplot(predictions)\n",
    "    c = Counter(predictions)\n",
    "    return [(i, c[i] / len(predictions) * 100.0) for i, count in c.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "file = dataset.filename.sample(n=1).values[0]\n",
    "file_probability(file, clas, preprocess, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset.filename == file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
